{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning and Optimizing Neural Networks - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've practiced regularization, initialization, and optimization techniques, its time to synthesize these concepts into a cohesive modeling pipeline.  \n",
    "\n",
    "With this pipeline, you will not only fit an initial model but also attempt to improve it. Your final model selection will pertain to the test metrics across these models. This will more naturally simulate a problem you might be faced with in practice, and the various modeling decisions you are apt to encounter along the way.  \n",
    "\n",
    "Recall that our end objective is to achieve a balance between overfitting and underfitting. You've seen the bias variance trade-off, and the role of regularization in order to reduce overfitting on training data and improving generalization to new cases. Common frameworks for such a procedure include train/validate/test methodology when data is plentiful, and K-folds cross-validation for smaller, more limited datasets. In this lab, you'll perform the latter, as the dataset in question is fairly limited. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Apply normalization as a preprocessing technique \n",
    "* Implement a K-folds cross validation modeling pipeline for deep learning models \n",
    "* Apply regularization techniques to improve your model's performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "First, run the following cell to import all the neccessary libraries and classes you will need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:04:33.110520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Necessary libraries and classes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you'll be working with the *The Lending Club* data. \n",
    "\n",
    "- Import the data available in the file `'loan_final.csv'` \n",
    "- Drop rows with missing values in the `'total_pymnt'` column (this is your target column) \n",
    "- Print the first five rows of the data \n",
    "- Print the dimensions of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>application_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5863.155187</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>car</td>\n",
       "      <td>GA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1014.530000</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>small_business</td>\n",
       "      <td>IL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3005.666844</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>other</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.0</td>\n",
       "      <td>12231.890000</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>other</td>\n",
       "      <td>OR</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4066.908161</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt_inv        term int_rate  installment grade  \\\n",
       "0     5000.0           4975.0   36 months   10.65%       162.87     B   \n",
       "1     2500.0           2500.0   60 months   15.27%        59.83     C   \n",
       "2     2400.0           2400.0   36 months   15.96%        84.33     C   \n",
       "3    10000.0          10000.0   36 months   13.49%       339.31     C   \n",
       "4     3000.0           3000.0   60 months   12.69%        67.79     B   \n",
       "\n",
       "  emp_length home_ownership  annual_inc verification_status  loan_status  \\\n",
       "0  10+ years           RENT     24000.0            Verified   Fully Paid   \n",
       "1   < 1 year           RENT     30000.0     Source Verified  Charged Off   \n",
       "2  10+ years           RENT     12252.0        Not Verified   Fully Paid   \n",
       "3  10+ years           RENT     49200.0     Source Verified   Fully Paid   \n",
       "4     1 year           RENT     80000.0     Source Verified   Fully Paid   \n",
       "\n",
       "          purpose addr_state  total_acc   total_pymnt application_type  \n",
       "0     credit_card         AZ        9.0   5863.155187       Individual  \n",
       "1             car         GA        4.0   1014.530000       Individual  \n",
       "2  small_business         IL       10.0   3005.666844       Individual  \n",
       "3           other         CA       37.0  12231.890000       Individual  \n",
       "4           other         OR       38.0   4066.908161       Individual  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv('loan_final.csv')\n",
    "\n",
    "# Drop rows with no target value\n",
    "data.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Print the first five rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41394, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dimensions of data \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Hold Out Test Set\n",
    "\n",
    "While we will be using K-fold cross validation to select an optimal model, we still want a final hold out test set that is completely independent of any modeling decisions. As such, pull out a sample of 30% of the total available data. For consistency of results, use random seed 42. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to build the model\n",
    "features = ['loan_amnt', 'funded_amnt_inv', 'installment', 'annual_inc', \n",
    "            'home_ownership', 'verification_status', 'emp_length']\n",
    "\n",
    "X = data[features]\n",
    "y = data[['total_pymnt']]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (Numerical features) \n",
    "\n",
    "- Fill all missing values in numeric features with their respective means \n",
    "- Standardize all the numeric features  \n",
    "- Convert the final results into DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select continuous features\n",
    "cont_features = ['loan_amnt', 'funded_amnt_inv', 'installment', 'annual_inc']\n",
    "\n",
    "X_train_cont = X_train.loc[:, cont_features]\n",
    "X_test_cont = X_test.loc[:, cont_features]\n",
    "\n",
    "# Instantiate SimpleImputer - fill the missing values with the mean\n",
    "si = SimpleImputer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_imputed = si.fit_transform(X_train_cont)\n",
    "\n",
    "# Transform test data\n",
    "X_test_imputed = si.transform(X_test_cont)\n",
    "\n",
    "# Instantiate StandardScaler\n",
    "ss_X = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = pd.DataFrame(ss_X.fit_transform(X_train_imputed),\n",
    "                              columns=X_train_cont.columns,\n",
    "                              index=X_train_cont.index)\n",
    "\n",
    "# Transform test data\n",
    "X_test_scaled = pd.DataFrame(ss_X.transform(X_test_imputed),\n",
    "                             columns=X_test_cont.columns,\n",
    "                             index=X_test_cont.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (Categorical features) \n",
    "\n",
    "- Fill all missing values in categorical features with the string `'missing'` \n",
    "- One-hot encode all categorical features \n",
    "- Convert the final results into DataFrames \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/envs/nn/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Select only the categorical features\n",
    "cat_features = ['home_ownership', 'verification_status', 'emp_length']\n",
    "X_train_cat = X_train.loc[:, cat_features]\n",
    "X_test_cat = X_test.loc[:, cat_features]\n",
    "\n",
    "# Fill missing values with the string 'missing'\n",
    "X_train_cat.fillna('missing', axis=0, inplace=True)\n",
    "X_test_cat.fillna('missing', axis=0, inplace=True)\n",
    "\n",
    "# OneHotEncode categorical variables\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# Transform training and test sets\n",
    "X_train_ohe = ohe.fit_transform(X_train_cat)\n",
    "X_test_ohe = ohe.transform(X_test_cat)\n",
    "\n",
    "# Get all categorical feature names\n",
    "cat_columns = ohe.get_feature_names(input_features=X_train_cat.columns)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_categorical = pd.DataFrame(X_train_ohe,\n",
    "                                   columns=cat_columns,\n",
    "                                   index=X_train_cat.index)\n",
    "\n",
    "# Transform test data\n",
    "X_test_categorical = pd.DataFrame(X_test_ohe,\n",
    "                                  columns=cat_columns,\n",
    "                                  index=X_test_cat.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cell to combine the numeric and categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine continuous and categorical feature DataFrames\n",
    "X_train_all = pd.concat([X_train_scaled, X_train_categorical], axis=1)\n",
    "X_test_all = pd.concat([X_test_scaled, X_test_categorical], axis=1)\n",
    "\n",
    "# Number of input features\n",
    "n_features = X_train_all.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardize the target DataFrames (`y_train` and `y_test`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate StandardScaler\n",
    "ss_y = StandardScaler()\n",
    "\n",
    "# Fit and transform Y (train)\n",
    "y_train_scaled = ss_y.fit_transform(y_train)\n",
    "\n",
    "# Transform test Y (test)\n",
    "y_test_scaled = ss_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a K-fold Cross Validation Methodology\n",
    "\n",
    "Now that your have a complete holdout test set, you will perform k-fold cross-validation using the following steps: \n",
    "\n",
    "- Create a function that returns a compiled deep learning model \n",
    "- Use the wrapper function `KerasRegressor()` that defines how these folds are trained \n",
    "- Call the `cross_val_predict()` function to perform k-fold cross-validation \n",
    "\n",
    "In the cell below, we've defined a baseline model that returns a compiled Keras models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that returns a compiled Keras model \n",
    "def create_baseline_model():\n",
    "    \n",
    "    # Initialize model\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(layers.Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "\n",
    "    # Second hidden layer\n",
    "    model.add(layers.Dense(5, activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='SGD', \n",
    "                  loss='mse',  \n",
    "                  metrics=['mse']) \n",
    "    \n",
    "    # Return the compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap `create_baseline_model` inside a call to `KerasRegressor()`, and: \n",
    "\n",
    "- Train for 150 epochs \n",
    "- Set the batch size to 256 \n",
    "\n",
    "> NOTE: Refer to the [documentation](https://keras.io/scikit-learn-api/) to learn about `KerasRegressor()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:06:54.897349: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Wrap the above function for use in cross-validation\n",
    "keras_wrapper_1 = KerasRegressor(create_baseline_model(), epochs=150, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cross_val_predict()` to generate cross-validated predictions with: \n",
    "- 5-fold cv \n",
    "- scaled input (`X_train_all`) and output (`y_train_scaled`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3b95103f93e24deeba0ccef28fb92545/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3b95103f93e24deeba0ccef28fb92545/assets\n",
      "2023-03-13 14:07:05.068022: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://bd189ff07c934b6da6ff4f22c2c56bbd: INVALID_ARGUMENT: ram://bd189ff07c934b6da6ff4f22c2c56bbd is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "91/91 [==============================] - 0s 855us/step - loss: 0.6882 - mse: 0.6882\n",
      "Epoch 2/150\n",
      "91/91 [==============================] - 0s 767us/step - loss: 0.2907 - mse: 0.2907\n",
      "Epoch 3/150\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.2466 - mse: 0.2466\n",
      "Epoch 4/150\n",
      "91/91 [==============================] - 0s 714us/step - loss: 0.2362 - mse: 0.2362\n",
      "Epoch 5/150\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2298 - mse: 0.2298\n",
      "Epoch 6/150\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.2253 - mse: 0.2253\n",
      "Epoch 7/150\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.2217 - mse: 0.2217\n",
      "Epoch 8/150\n",
      "91/91 [==============================] - 0s 798us/step - loss: 0.2186 - mse: 0.2186\n",
      "Epoch 9/150\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.2160 - mse: 0.2160\n",
      "Epoch 10/150\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.2139 - mse: 0.2139\n",
      "Epoch 11/150\n",
      "91/91 [==============================] - 0s 775us/step - loss: 0.2119 - mse: 0.2119\n",
      "Epoch 12/150\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.2103 - mse: 0.2103\n",
      "Epoch 13/150\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.2089 - mse: 0.2089\n",
      "Epoch 14/150\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.2079 - mse: 0.2079\n",
      "Epoch 15/150\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.2065 - mse: 0.2065\n",
      "Epoch 16/150\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.2058 - mse: 0.2058\n",
      "Epoch 17/150\n",
      "91/91 [==============================] - 0s 662us/step - loss: 0.2050 - mse: 0.2050\n",
      "Epoch 18/150\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.2043 - mse: 0.2043\n",
      "Epoch 19/150\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.2036 - mse: 0.2036\n",
      "Epoch 20/150\n",
      "91/91 [==============================] - 0s 717us/step - loss: 0.2030 - mse: 0.2030\n",
      "Epoch 21/150\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.2023 - mse: 0.2023\n",
      "Epoch 22/150\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2019 - mse: 0.2019\n",
      "Epoch 23/150\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.2014 - mse: 0.2014\n",
      "Epoch 24/150\n",
      "91/91 [==============================] - 0s 813us/step - loss: 0.2008 - mse: 0.2008\n",
      "Epoch 25/150\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.2008 - mse: 0.2008\n",
      "Epoch 26/150\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.2001 - mse: 0.2001\n",
      "Epoch 27/150\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.2000 - mse: 0.2000\n",
      "Epoch 28/150\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1995 - mse: 0.1995\n",
      "Epoch 29/150\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.1993 - mse: 0.1993\n",
      "Epoch 30/150\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1990 - mse: 0.1990\n",
      "Epoch 31/150\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1988 - mse: 0.1988\n",
      "Epoch 32/150\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1985 - mse: 0.1985\n",
      "Epoch 33/150\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1984 - mse: 0.1984\n",
      "Epoch 34/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1980 - mse: 0.1980\n",
      "Epoch 35/150\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.1978 - mse: 0.1978\n",
      "Epoch 36/150\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1977 - mse: 0.1977\n",
      "Epoch 37/150\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.1975 - mse: 0.1975\n",
      "Epoch 38/150\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1973 - mse: 0.1973\n",
      "Epoch 39/150\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.1973 - mse: 0.1973\n",
      "Epoch 40/150\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1970 - mse: 0.1970\n",
      "Epoch 41/150\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.1968 - mse: 0.1968\n",
      "Epoch 42/150\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 43/150\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 44/150\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1962 - mse: 0.1962\n",
      "Epoch 45/150\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1962 - mse: 0.1962\n",
      "Epoch 46/150\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1961 - mse: 0.1961\n",
      "Epoch 47/150\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1958 - mse: 0.1958\n",
      "Epoch 48/150\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.1959 - mse: 0.1959\n",
      "Epoch 49/150\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1957 - mse: 0.1957\n",
      "Epoch 50/150\n",
      "91/91 [==============================] - 0s 660us/step - loss: 0.1955 - mse: 0.1955\n",
      "Epoch 51/150\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.1955 - mse: 0.1955\n",
      "Epoch 52/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.1952 - mse: 0.1952\n",
      "Epoch 53/150\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1952 - mse: 0.1952\n",
      "Epoch 54/150\n",
      "91/91 [==============================] - 0s 618us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 55/150\n",
      "91/91 [==============================] - 0s 630us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 56/150\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 57/150\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 58/150\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1947 - mse: 0.1947\n",
      "Epoch 59/150\n",
      "91/91 [==============================] - 0s 706us/step - loss: 0.1947 - mse: 0.1947\n",
      "Epoch 60/150\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.1945 - mse: 0.1945\n",
      "Epoch 61/150\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 62/150\n",
      "91/91 [==============================] - 0s 706us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 63/150\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 64/150\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 65/150\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 66/150\n",
      "91/91 [==============================] - 0s 710us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 67/150\n",
      "91/91 [==============================] - 0s 706us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 68/150\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1938 - mse: 0.1938\n",
      "Epoch 69/150\n",
      "91/91 [==============================] - 0s 716us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 70/150\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1935 - mse: 0.1935\n",
      "Epoch 71/150\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1935 - mse: 0.1935\n",
      "Epoch 72/150\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1934 - mse: 0.1934\n",
      "Epoch 73/150\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1933 - mse: 0.1933\n",
      "Epoch 74/150\n",
      "91/91 [==============================] - 0s 790us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 75/150\n",
      "91/91 [==============================] - 0s 721us/step - loss: 0.1931 - mse: 0.1931\n",
      "Epoch 76/150\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.1931 - mse: 0.1931\n",
      "Epoch 77/150\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 78/150\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 79/150\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 80/150\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 81/150\n",
      "91/91 [==============================] - 0s 664us/step - loss: 0.1927 - mse: 0.1927\n",
      "Epoch 82/150\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 83/150\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 84/150\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 722us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 86/150\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 87/150\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 88/150\n",
      "91/91 [==============================] - 0s 654us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 89/150\n",
      "91/91 [==============================] - 0s 621us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 90/150\n",
      "91/91 [==============================] - 0s 623us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 91/150\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 92/150\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 93/150\n",
      "91/91 [==============================] - 0s 662us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 94/150\n",
      "91/91 [==============================] - 0s 634us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 95/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 96/150\n",
      "91/91 [==============================] - 0s 779us/step - loss: 0.1916 - mse: 0.1916\n",
      "Epoch 97/150\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 98/150\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 99/150\n",
      "91/91 [==============================] - 0s 616us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 100/150\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 101/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 102/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 103/150\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 104/150\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 105/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 106/150\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 107/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 108/150\n",
      "91/91 [==============================] - 0s 879us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 109/150\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 110/150\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 111/150\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 112/150\n",
      "91/91 [==============================] - 0s 602us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 113/150\n",
      "91/91 [==============================] - 0s 626us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 114/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 115/150\n",
      "91/91 [==============================] - 0s 635us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 116/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 117/150\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 118/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1901 - mse: 0.1901\n",
      "Epoch 119/150\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 120/150\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 121/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 122/150\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.1899 - mse: 0.1899\n",
      "Epoch 123/150\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1897 - mse: 0.1897\n",
      "Epoch 124/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.1899 - mse: 0.1899\n",
      "Epoch 125/150\n",
      "91/91 [==============================] - 0s 639us/step - loss: 0.1896 - mse: 0.1896\n",
      "Epoch 126/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1896 - mse: 0.1896\n",
      "Epoch 127/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1896 - mse: 0.1896\n",
      "Epoch 128/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1896 - mse: 0.1896\n",
      "Epoch 129/150\n",
      "91/91 [==============================] - 0s 660us/step - loss: 0.1894 - mse: 0.1894\n",
      "Epoch 130/150\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.1894 - mse: 0.1894\n",
      "Epoch 131/150\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.1893 - mse: 0.1893\n",
      "Epoch 132/150\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 133/150\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 134/150\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 135/150\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 136/150\n",
      "91/91 [==============================] - 0s 710us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 137/150\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.1890 - mse: 0.1890\n",
      "Epoch 138/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 139/150\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 140/150\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 141/150\n",
      "91/91 [==============================] - 0s 660us/step - loss: 0.1887 - mse: 0.1887\n",
      "Epoch 142/150\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.1888 - mse: 0.1888\n",
      "Epoch 143/150\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1887 - mse: 0.1887\n",
      "Epoch 144/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1887 - mse: 0.1887\n",
      "Epoch 145/150\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1886 - mse: 0.1886\n",
      "Epoch 146/150\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1885 - mse: 0.1885\n",
      "Epoch 147/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1883 - mse: 0.1883\n",
      "Epoch 148/150\n",
      "91/91 [==============================] - 0s 657us/step - loss: 0.1884 - mse: 0.1884\n",
      "Epoch 149/150\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.1884 - mse: 0.1884\n",
      "Epoch 150/150\n",
      "91/91 [==============================] - 0s 631us/step - loss: 0.1884 - mse: 0.1884\n",
      "23/23 [==============================] - 0s 580us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4779d3c3c04248af8c68abde132eb673/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4779d3c3c04248af8c68abde132eb673/assets\n",
      "2023-03-13 14:07:15.680837: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://39bea347579c492e96c9af02f16b77a1: INVALID_ARGUMENT: ram://39bea347579c492e96c9af02f16b77a1 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.6913 - mse: 0.6913\n",
      "Epoch 2/150\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.2959 - mse: 0.2959\n",
      "Epoch 3/150\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.2515 - mse: 0.2515\n",
      "Epoch 4/150\n",
      "91/91 [==============================] - 0s 662us/step - loss: 0.2411 - mse: 0.2411\n",
      "Epoch 5/150\n",
      "91/91 [==============================] - 0s 656us/step - loss: 0.2348 - mse: 0.2348\n",
      "Epoch 6/150\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.2303 - mse: 0.2303\n",
      "Epoch 7/150\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.2265 - mse: 0.2265\n",
      "Epoch 8/150\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.2237 - mse: 0.2237\n",
      "Epoch 9/150\n",
      "91/91 [==============================] - 0s 792us/step - loss: 0.2212 - mse: 0.2212\n",
      "Epoch 10/150\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.2191 - mse: 0.2191\n",
      "Epoch 11/150\n",
      "91/91 [==============================] - 0s 711us/step - loss: 0.2173 - mse: 0.2173\n",
      "Epoch 12/150\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.2156 - mse: 0.2156\n",
      "Epoch 13/150\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.2143 - mse: 0.2143\n",
      "Epoch 14/150\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.2131 - mse: 0.2131\n",
      "Epoch 15/150\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.2120 - mse: 0.2120\n",
      "Epoch 16/150\n",
      "91/91 [==============================] - 0s 808us/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 17/150\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2103 - mse: 0.2103\n",
      "Epoch 18/150\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2094 - mse: 0.2094\n",
      "Epoch 19/150\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.2088 - mse: 0.2088\n",
      "Epoch 20/150\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.2081 - mse: 0.2081\n",
      "Epoch 21/150\n",
      "91/91 [==============================] - 0s 653us/step - loss: 0.2076 - mse: 0.2076\n",
      "Epoch 22/150\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.2073 - mse: 0.2073\n",
      "Epoch 23/150\n",
      "91/91 [==============================] - 0s 649us/step - loss: 0.2066 - mse: 0.2066\n",
      "Epoch 24/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.2062 - mse: 0.2062\n",
      "Epoch 25/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.2058 - mse: 0.2058\n",
      "Epoch 26/150\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.2055 - mse: 0.2055\n",
      "Epoch 27/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.2051 - mse: 0.2051\n",
      "Epoch 28/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.2048 - mse: 0.2048\n",
      "Epoch 29/150\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.2045 - mse: 0.2045\n",
      "Epoch 30/150\n",
      "91/91 [==============================] - 0s 649us/step - loss: 0.2042 - mse: 0.2042\n",
      "Epoch 31/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.2042 - mse: 0.2042\n",
      "Epoch 32/150\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.2037 - mse: 0.2037\n",
      "Epoch 33/150\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.2037 - mse: 0.2037\n",
      "Epoch 34/150\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.2034 - mse: 0.2034\n",
      "Epoch 35/150\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.2032 - mse: 0.2032\n",
      "Epoch 36/150\n",
      "91/91 [==============================] - 0s 656us/step - loss: 0.2030 - mse: 0.2030\n",
      "Epoch 37/150\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.2029 - mse: 0.2029\n",
      "Epoch 38/150\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.2025 - mse: 0.2025\n",
      "Epoch 39/150\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.2025 - mse: 0.2025\n",
      "Epoch 40/150\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.2023 - mse: 0.2023\n",
      "Epoch 41/150\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.2022 - mse: 0.2022\n",
      "Epoch 42/150\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.2020 - mse: 0.2020\n",
      "Epoch 43/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.2018 - mse: 0.2018\n",
      "Epoch 44/150\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.2017 - mse: 0.2017\n",
      "Epoch 45/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.2016 - mse: 0.2016\n",
      "Epoch 46/150\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.2015 - mse: 0.2015\n",
      "Epoch 47/150\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2015 - mse: 0.2015\n",
      "Epoch 48/150\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.2012 - mse: 0.2012\n",
      "Epoch 49/150\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.2011 - mse: 0.2011\n",
      "Epoch 50/150\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2012 - mse: 0.2012\n",
      "Epoch 51/150\n",
      "91/91 [==============================] - 0s 775us/step - loss: 0.2009 - mse: 0.2009\n",
      "Epoch 52/150\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.2009 - mse: 0.2009\n",
      "Epoch 53/150\n",
      "91/91 [==============================] - 0s 774us/step - loss: 0.2008 - mse: 0.2008\n",
      "Epoch 54/150\n",
      "91/91 [==============================] - 0s 793us/step - loss: 0.2006 - mse: 0.2006\n",
      "Epoch 55/150\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2005 - mse: 0.2005\n",
      "Epoch 56/150\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.2005 - mse: 0.2005\n",
      "Epoch 57/150\n",
      "91/91 [==============================] - 0s 641us/step - loss: 0.2004 - mse: 0.2004\n",
      "Epoch 58/150\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.2002 - mse: 0.2002\n",
      "Epoch 59/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.2002 - mse: 0.2002\n",
      "Epoch 60/150\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.2000 - mse: 0.2000\n",
      "Epoch 61/150\n",
      "91/91 [==============================] - 0s 628us/step - loss: 0.1998 - mse: 0.1998\n",
      "Epoch 62/150\n",
      "91/91 [==============================] - 0s 635us/step - loss: 0.2000 - mse: 0.2000\n",
      "Epoch 63/150\n",
      "91/91 [==============================] - 0s 613us/step - loss: 0.1998 - mse: 0.1998\n",
      "Epoch 64/150\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1998 - mse: 0.1998\n",
      "Epoch 65/150\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1996 - mse: 0.1996\n",
      "Epoch 66/150\n",
      "91/91 [==============================] - 0s 623us/step - loss: 0.1997 - mse: 0.1997\n",
      "Epoch 67/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1995 - mse: 0.1995\n",
      "Epoch 68/150\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.1994 - mse: 0.1994\n",
      "Epoch 69/150\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.1992 - mse: 0.1992\n",
      "Epoch 70/150\n",
      "91/91 [==============================] - 0s 786us/step - loss: 0.1993 - mse: 0.1993\n",
      "Epoch 71/150\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1992 - mse: 0.1992\n",
      "Epoch 72/150\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1990 - mse: 0.1990\n",
      "Epoch 73/150\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1990 - mse: 0.1990\n",
      "Epoch 74/150\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.1989 - mse: 0.1989\n",
      "Epoch 75/150\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1988 - mse: 0.1988\n",
      "Epoch 76/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.1988 - mse: 0.1988\n",
      "Epoch 77/150\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.1987 - mse: 0.1987\n",
      "Epoch 78/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1985 - mse: 0.1985\n",
      "Epoch 79/150\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1986 - mse: 0.1986\n",
      "Epoch 80/150\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.1984 - mse: 0.1984\n",
      "Epoch 81/150\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.1983 - mse: 0.1983\n",
      "Epoch 82/150\n",
      "91/91 [==============================] - 0s 719us/step - loss: 0.1984 - mse: 0.1984\n",
      "Epoch 83/150\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1984 - mse: 0.1984\n",
      "Epoch 84/150\n",
      "91/91 [==============================] - 0s 621us/step - loss: 0.1983 - mse: 0.1983\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 606us/step - loss: 0.1982 - mse: 0.1982\n",
      "Epoch 86/150\n",
      "91/91 [==============================] - 0s 649us/step - loss: 0.1980 - mse: 0.1980\n",
      "Epoch 87/150\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.1980 - mse: 0.1980\n",
      "Epoch 88/150\n",
      "91/91 [==============================] - 0s 711us/step - loss: 0.1979 - mse: 0.1979\n",
      "Epoch 89/150\n",
      "91/91 [==============================] - 0s 618us/step - loss: 0.1979 - mse: 0.1979\n",
      "Epoch 90/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1979 - mse: 0.1979\n",
      "Epoch 91/150\n",
      "91/91 [==============================] - 0s 613us/step - loss: 0.1977 - mse: 0.1977\n",
      "Epoch 92/150\n",
      "91/91 [==============================] - 0s 633us/step - loss: 0.1975 - mse: 0.1975\n",
      "Epoch 93/150\n",
      "91/91 [==============================] - 0s 641us/step - loss: 0.1976 - mse: 0.1976\n",
      "Epoch 94/150\n",
      "91/91 [==============================] - 0s 615us/step - loss: 0.1976 - mse: 0.1976\n",
      "Epoch 95/150\n",
      "91/91 [==============================] - 0s 618us/step - loss: 0.1974 - mse: 0.1974\n",
      "Epoch 96/150\n",
      "91/91 [==============================] - 0s 616us/step - loss: 0.1973 - mse: 0.1973\n",
      "Epoch 97/150\n",
      "91/91 [==============================] - 0s 617us/step - loss: 0.1973 - mse: 0.1973\n",
      "Epoch 98/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1973 - mse: 0.1973\n",
      "Epoch 99/150\n",
      "91/91 [==============================] - 0s 645us/step - loss: 0.1973 - mse: 0.1973\n",
      "Epoch 100/150\n",
      "91/91 [==============================] - 0s 633us/step - loss: 0.1973 - mse: 0.1973\n",
      "Epoch 101/150\n",
      "91/91 [==============================] - 0s 623us/step - loss: 0.1971 - mse: 0.1971\n",
      "Epoch 102/150\n",
      "91/91 [==============================] - 0s 626us/step - loss: 0.1970 - mse: 0.1970\n",
      "Epoch 103/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.1970 - mse: 0.1970\n",
      "Epoch 104/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 105/150\n",
      "91/91 [==============================] - 0s 638us/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 106/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.1968 - mse: 0.1968\n",
      "Epoch 107/150\n",
      "91/91 [==============================] - 0s 605us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 108/150\n",
      "91/91 [==============================] - 0s 605us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 109/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1966 - mse: 0.1966\n",
      "Epoch 110/150\n",
      "91/91 [==============================] - 0s 619us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 111/150\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 112/150\n",
      "91/91 [==============================] - 0s 649us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 113/150\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 114/150\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1963 - mse: 0.1963\n",
      "Epoch 115/150\n",
      "91/91 [==============================] - 0s 630us/step - loss: 0.1962 - mse: 0.1962\n",
      "Epoch 116/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.1960 - mse: 0.1960\n",
      "Epoch 117/150\n",
      "91/91 [==============================] - 0s 639us/step - loss: 0.1961 - mse: 0.1961\n",
      "Epoch 118/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1960 - mse: 0.1960\n",
      "Epoch 119/150\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1960 - mse: 0.1960\n",
      "Epoch 120/150\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 121/150\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1958 - mse: 0.1958\n",
      "Epoch 122/150\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 123/150\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.1957 - mse: 0.1957\n",
      "Epoch 124/150\n",
      "91/91 [==============================] - 0s 619us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 125/150\n",
      "91/91 [==============================] - 0s 623us/step - loss: 0.1957 - mse: 0.1957\n",
      "Epoch 126/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 127/150\n",
      "91/91 [==============================] - 0s 626us/step - loss: 0.1955 - mse: 0.1955\n",
      "Epoch 128/150\n",
      "91/91 [==============================] - 0s 621us/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 129/150\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1953 - mse: 0.1953\n",
      "Epoch 130/150\n",
      "91/91 [==============================] - 0s 662us/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 131/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 132/150\n",
      "91/91 [==============================] - 0s 723us/step - loss: 0.1953 - mse: 0.1953\n",
      "Epoch 133/150\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 134/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 135/150\n",
      "91/91 [==============================] - 0s 617us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 136/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 137/150\n",
      "91/91 [==============================] - 0s 614us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 138/150\n",
      "91/91 [==============================] - 0s 631us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 139/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 140/150\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 141/150\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 142/150\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.1947 - mse: 0.1947\n",
      "Epoch 143/150\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 144/150\n",
      "91/91 [==============================] - 0s 660us/step - loss: 0.1944 - mse: 0.1944\n",
      "Epoch 145/150\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1944 - mse: 0.1944\n",
      "Epoch 146/150\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1944 - mse: 0.1944\n",
      "Epoch 147/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 148/150\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 149/150\n",
      "91/91 [==============================] - 0s 623us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 150/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1940 - mse: 0.1940\n",
      "23/23 [==============================] - 0s 579us/step\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a85916ce66b645f69fed0159a0e8c12d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a85916ce66b645f69fed0159a0e8c12d/assets\n",
      "2023-03-13 14:07:25.817719: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://5b1b8abc04d64121aada769584f797ce: INVALID_ARGUMENT: ram://5b1b8abc04d64121aada769584f797ce is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.6833 - mse: 0.6833\n",
      "Epoch 2/150\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.2915 - mse: 0.2915\n",
      "Epoch 3/150\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.2472 - mse: 0.2472\n",
      "Epoch 4/150\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.2366 - mse: 0.2366\n",
      "Epoch 5/150\n",
      "91/91 [==============================] - 0s 709us/step - loss: 0.2305 - mse: 0.2305\n",
      "Epoch 6/150\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.2259 - mse: 0.2259\n",
      "Epoch 7/150\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.2223 - mse: 0.2223\n",
      "Epoch 8/150\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.2192 - mse: 0.2192\n",
      "Epoch 9/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.2166 - mse: 0.2166\n",
      "Epoch 10/150\n",
      "91/91 [==============================] - 0s 641us/step - loss: 0.2145 - mse: 0.2145\n",
      "Epoch 11/150\n",
      "91/91 [==============================] - 0s 634us/step - loss: 0.2127 - mse: 0.2127\n",
      "Epoch 12/150\n",
      "91/91 [==============================] - 0s 641us/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 13/150\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.2096 - mse: 0.2096\n",
      "Epoch 14/150\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.2085 - mse: 0.2085\n",
      "Epoch 15/150\n",
      "91/91 [==============================] - 0s 784us/step - loss: 0.2074 - mse: 0.2074\n",
      "Epoch 16/150\n",
      "91/91 [==============================] - 0s 808us/step - loss: 0.2064 - mse: 0.2064\n",
      "Epoch 17/150\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.2056 - mse: 0.2056\n",
      "Epoch 18/150\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.2050 - mse: 0.2050\n",
      "Epoch 19/150\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.2043 - mse: 0.2043\n",
      "Epoch 20/150\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.2037 - mse: 0.2037\n",
      "Epoch 21/150\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.2031 - mse: 0.2031\n",
      "Epoch 22/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.2022 - mse: 0.2022\n",
      "Epoch 23/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.2021 - mse: 0.2021\n",
      "Epoch 24/150\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.2017 - mse: 0.2017\n",
      "Epoch 25/150\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.2013 - mse: 0.2013\n",
      "Epoch 26/150\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.2009 - mse: 0.2009\n",
      "Epoch 27/150\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.2005 - mse: 0.2005\n",
      "Epoch 28/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.1999 - mse: 0.1999\n",
      "Epoch 29/150\n",
      "91/91 [==============================] - 0s 701us/step - loss: 0.2000 - mse: 0.2000\n",
      "Epoch 30/150\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1997 - mse: 0.1997\n",
      "Epoch 31/150\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1995 - mse: 0.1995\n",
      "Epoch 32/150\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1994 - mse: 0.1994\n",
      "Epoch 33/150\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.1991 - mse: 0.1991\n",
      "Epoch 34/150\n",
      "91/91 [==============================] - 0s 649us/step - loss: 0.1988 - mse: 0.1988\n",
      "Epoch 35/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.1986 - mse: 0.1986\n",
      "Epoch 36/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1983 - mse: 0.1983\n",
      "Epoch 37/150\n",
      "91/91 [==============================] - 0s 615us/step - loss: 0.1983 - mse: 0.1983\n",
      "Epoch 38/150\n",
      "91/91 [==============================] - 0s 639us/step - loss: 0.1983 - mse: 0.1983\n",
      "Epoch 39/150\n",
      "91/91 [==============================] - 0s 726us/step - loss: 0.1979 - mse: 0.1979\n",
      "Epoch 40/150\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1978 - mse: 0.1978\n",
      "Epoch 41/150\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1974 - mse: 0.1974\n",
      "Epoch 42/150\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1975 - mse: 0.1975\n",
      "Epoch 43/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1974 - mse: 0.1974\n",
      "Epoch 44/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1972 - mse: 0.1972\n",
      "Epoch 45/150\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1970 - mse: 0.1970\n",
      "Epoch 46/150\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.1970 - mse: 0.1970\n",
      "Epoch 47/150\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 48/150\n",
      "91/91 [==============================] - 0s 808us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 49/150\n",
      "91/91 [==============================] - 0s 777us/step - loss: 0.1966 - mse: 0.1966\n",
      "Epoch 50/150\n",
      "91/91 [==============================] - 0s 784us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 51/150\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.1963 - mse: 0.1963\n",
      "Epoch 52/150\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 53/150\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.1962 - mse: 0.1962\n",
      "Epoch 54/150\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1963 - mse: 0.1963\n",
      "Epoch 55/150\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1960 - mse: 0.1960\n",
      "Epoch 56/150\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1961 - mse: 0.1961\n",
      "Epoch 57/150\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1958 - mse: 0.1958\n",
      "Epoch 58/150\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.1958 - mse: 0.1958\n",
      "Epoch 59/150\n",
      "91/91 [==============================] - 0s 662us/step - loss: 0.1957 - mse: 0.1957\n",
      "Epoch 60/150\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 61/150\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 62/150\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.1955 - mse: 0.1955\n",
      "Epoch 63/150\n",
      "91/91 [==============================] - 0s 701us/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 64/150\n",
      "91/91 [==============================] - 0s 656us/step - loss: 0.1953 - mse: 0.1953\n",
      "Epoch 65/150\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 66/150\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.1952 - mse: 0.1952\n",
      "Epoch 67/150\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 68/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 69/150\n",
      "91/91 [==============================] - 0s 649us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 70/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 71/150\n",
      "91/91 [==============================] - 0s 625us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 72/150\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 73/150\n",
      "91/91 [==============================] - 0s 662us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 74/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1945 - mse: 0.1945\n",
      "Epoch 75/150\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.1945 - mse: 0.1945\n",
      "Epoch 76/150\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1944 - mse: 0.1944\n",
      "Epoch 77/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 78/150\n",
      "91/91 [==============================] - 0s 645us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 79/150\n",
      "91/91 [==============================] - 0s 653us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 80/150\n",
      "91/91 [==============================] - 0s 654us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 81/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 82/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 83/150\n",
      "91/91 [==============================] - 0s 650us/step - loss: 0.1938 - mse: 0.1938\n",
      "Epoch 84/150\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1938 - mse: 0.1938\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 648us/step - loss: 0.1938 - mse: 0.1938\n",
      "Epoch 86/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.1936 - mse: 0.1936\n",
      "Epoch 87/150\n",
      "91/91 [==============================] - 0s 653us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 88/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.1936 - mse: 0.1936\n",
      "Epoch 89/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1935 - mse: 0.1935\n",
      "Epoch 90/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.1935 - mse: 0.1935\n",
      "Epoch 91/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 92/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 93/150\n",
      "91/91 [==============================] - 0s 656us/step - loss: 0.1933 - mse: 0.1933\n",
      "Epoch 94/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.1931 - mse: 0.1931\n",
      "Epoch 95/150\n",
      "91/91 [==============================] - 0s 650us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 96/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 97/150\n",
      "91/91 [==============================] - 0s 626us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 98/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 99/150\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 100/150\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 101/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 102/150\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 103/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 104/150\n",
      "91/91 [==============================] - 0s 623us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 105/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 106/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 107/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 108/150\n",
      "91/91 [==============================] - 0s 635us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 109/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 110/150\n",
      "91/91 [==============================] - 0s 654us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 111/150\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 112/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 113/150\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 114/150\n",
      "91/91 [==============================] - 0s 714us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 115/150\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 116/150\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 117/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 118/150\n",
      "91/91 [==============================] - 0s 638us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 119/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 120/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 121/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 122/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 123/150\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 124/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 125/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 126/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 127/150\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 128/150\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 129/150\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 130/150\n",
      "91/91 [==============================] - 0s 639us/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 131/150\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 132/150\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 133/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 134/150\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 135/150\n",
      "91/91 [==============================] - 0s 653us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 136/150\n",
      "91/91 [==============================] - 0s 653us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 137/150\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 138/150\n",
      "91/91 [==============================] - 0s 662us/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 139/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 140/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 141/150\n",
      "91/91 [==============================] - 0s 658us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 142/150\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 143/150\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 144/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 145/150\n",
      "91/91 [==============================] - 0s 701us/step - loss: 0.1901 - mse: 0.1901\n",
      "Epoch 146/150\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 147/150\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 148/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 149/150\n",
      "91/91 [==============================] - 0s 650us/step - loss: 0.1901 - mse: 0.1901\n",
      "Epoch 150/150\n",
      "91/91 [==============================] - 0s 650us/step - loss: 0.1900 - mse: 0.1900\n",
      "23/23 [==============================] - 0s 595us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://542a2c7edc5c4633adc833f2e109b3a0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://542a2c7edc5c4633adc833f2e109b3a0/assets\n",
      "2023-03-13 14:07:35.778170: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://2ee9e06cfbef4e2d8fb5089212162731: INVALID_ARGUMENT: ram://2ee9e06cfbef4e2d8fb5089212162731 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.6881 - mse: 0.6881\n",
      "Epoch 2/150\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.2907 - mse: 0.2907\n",
      "Epoch 3/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.2475 - mse: 0.2475\n",
      "Epoch 4/150\n",
      "91/91 [==============================] - 0s 610us/step - loss: 0.2376 - mse: 0.2376\n",
      "Epoch 5/150\n",
      "91/91 [==============================] - 0s 639us/step - loss: 0.2315 - mse: 0.2315\n",
      "Epoch 6/150\n",
      "91/91 [==============================] - 0s 619us/step - loss: 0.2270 - mse: 0.2270\n",
      "Epoch 7/150\n",
      "91/91 [==============================] - 0s 628us/step - loss: 0.2234 - mse: 0.2234\n",
      "Epoch 8/150\n",
      "91/91 [==============================] - 0s 660us/step - loss: 0.2204 - mse: 0.2204\n",
      "Epoch 9/150\n",
      "91/91 [==============================] - 0s 767us/step - loss: 0.2178 - mse: 0.2178\n",
      "Epoch 10/150\n",
      "91/91 [==============================] - 0s 706us/step - loss: 0.2155 - mse: 0.2155\n",
      "Epoch 11/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.2139 - mse: 0.2139\n",
      "Epoch 12/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.2121 - mse: 0.2121\n",
      "Epoch 13/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.2107 - mse: 0.2107\n",
      "Epoch 14/150\n",
      "91/91 [==============================] - 0s 635us/step - loss: 0.2096 - mse: 0.2096\n",
      "Epoch 15/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.2086 - mse: 0.2086\n",
      "Epoch 16/150\n",
      "91/91 [==============================] - 0s 625us/step - loss: 0.2078 - mse: 0.2078\n",
      "Epoch 17/150\n",
      "91/91 [==============================] - 0s 625us/step - loss: 0.2068 - mse: 0.2068\n",
      "Epoch 18/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.2061 - mse: 0.2061\n",
      "Epoch 19/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.2055 - mse: 0.2055\n",
      "Epoch 20/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.2050 - mse: 0.2050\n",
      "Epoch 21/150\n",
      "91/91 [==============================] - 0s 650us/step - loss: 0.2042 - mse: 0.2042\n",
      "Epoch 22/150\n",
      "91/91 [==============================] - 0s 639us/step - loss: 0.2038 - mse: 0.2038\n",
      "Epoch 23/150\n",
      "91/91 [==============================] - 0s 641us/step - loss: 0.2034 - mse: 0.2034\n",
      "Epoch 24/150\n",
      "91/91 [==============================] - 0s 869us/step - loss: 0.2029 - mse: 0.2029\n",
      "Epoch 25/150\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.2025 - mse: 0.2025\n",
      "Epoch 26/150\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.2021 - mse: 0.2021\n",
      "Epoch 27/150\n",
      "91/91 [==============================] - 0s 639us/step - loss: 0.2016 - mse: 0.2016\n",
      "Epoch 28/150\n",
      "91/91 [==============================] - 0s 785us/step - loss: 0.2015 - mse: 0.2015\n",
      "Epoch 29/150\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.2012 - mse: 0.2012\n",
      "Epoch 30/150\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.2010 - mse: 0.2010\n",
      "Epoch 31/150\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2007 - mse: 0.2007\n",
      "Epoch 32/150\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.2004 - mse: 0.2004\n",
      "Epoch 33/150\n",
      "91/91 [==============================] - 0s 714us/step - loss: 0.2004 - mse: 0.2004\n",
      "Epoch 34/150\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.2000 - mse: 0.2000\n",
      "Epoch 35/150\n",
      "91/91 [==============================] - 0s 654us/step - loss: 0.2000 - mse: 0.2000\n",
      "Epoch 36/150\n",
      "91/91 [==============================] - 0s 635us/step - loss: 0.1998 - mse: 0.1998\n",
      "Epoch 37/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.1995 - mse: 0.1995\n",
      "Epoch 38/150\n",
      "91/91 [==============================] - 0s 618us/step - loss: 0.1994 - mse: 0.1994\n",
      "Epoch 39/150\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.1993 - mse: 0.1993\n",
      "Epoch 40/150\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1991 - mse: 0.1991\n",
      "Epoch 41/150\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.1990 - mse: 0.1990\n",
      "Epoch 42/150\n",
      "91/91 [==============================] - 0s 635us/step - loss: 0.1990 - mse: 0.1990\n",
      "Epoch 43/150\n",
      "91/91 [==============================] - 0s 649us/step - loss: 0.1986 - mse: 0.1986\n",
      "Epoch 44/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1985 - mse: 0.1985\n",
      "Epoch 45/150\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.1984 - mse: 0.1984\n",
      "Epoch 46/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1982 - mse: 0.1982\n",
      "Epoch 47/150\n",
      "91/91 [==============================] - 0s 634us/step - loss: 0.1982 - mse: 0.1982\n",
      "Epoch 48/150\n",
      "91/91 [==============================] - 0s 634us/step - loss: 0.1982 - mse: 0.1982\n",
      "Epoch 49/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1980 - mse: 0.1980\n",
      "Epoch 50/150\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1977 - mse: 0.1977\n",
      "Epoch 51/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1977 - mse: 0.1977\n",
      "Epoch 52/150\n",
      "91/91 [==============================] - 0s 630us/step - loss: 0.1974 - mse: 0.1974\n",
      "Epoch 53/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1976 - mse: 0.1976\n",
      "Epoch 54/150\n",
      "91/91 [==============================] - 0s 628us/step - loss: 0.1974 - mse: 0.1974\n",
      "Epoch 55/150\n",
      "91/91 [==============================] - 0s 770us/step - loss: 0.1972 - mse: 0.1972\n",
      "Epoch 56/150\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1972 - mse: 0.1972\n",
      "Epoch 57/150\n",
      "91/91 [==============================] - 0s 656us/step - loss: 0.1972 - mse: 0.1972\n",
      "Epoch 58/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1970 - mse: 0.1970\n",
      "Epoch 59/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 60/150\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 61/150\n",
      "91/91 [==============================] - 0s 653us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 62/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1966 - mse: 0.1966\n",
      "Epoch 63/150\n",
      "91/91 [==============================] - 0s 618us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 64/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 65/150\n",
      "91/91 [==============================] - 0s 641us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 66/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.1963 - mse: 0.1963\n",
      "Epoch 67/150\n",
      "91/91 [==============================] - 0s 635us/step - loss: 0.1962 - mse: 0.1962\n",
      "Epoch 68/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1962 - mse: 0.1962\n",
      "Epoch 69/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1961 - mse: 0.1961\n",
      "Epoch 70/150\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.1961 - mse: 0.1961\n",
      "Epoch 71/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1959 - mse: 0.1959\n",
      "Epoch 72/150\n",
      "91/91 [==============================] - 0s 630us/step - loss: 0.1958 - mse: 0.1958\n",
      "Epoch 73/150\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1958 - mse: 0.1958\n",
      "Epoch 74/150\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1957 - mse: 0.1957\n",
      "Epoch 75/150\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1957 - mse: 0.1957\n",
      "Epoch 76/150\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 77/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1955 - mse: 0.1955\n",
      "Epoch 78/150\n",
      "91/91 [==============================] - 0s 649us/step - loss: 0.1955 - mse: 0.1955\n",
      "Epoch 79/150\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 80/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.1952 - mse: 0.1952\n",
      "Epoch 81/150\n",
      "91/91 [==============================] - 0s 634us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 82/150\n",
      "91/91 [==============================] - 0s 617us/step - loss: 0.1952 - mse: 0.1952\n",
      "Epoch 83/150\n",
      "91/91 [==============================] - 0s 630us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 84/150\n",
      "91/91 [==============================] - 0s 639us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 638us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 86/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 87/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 88/150\n",
      "91/91 [==============================] - 0s 626us/step - loss: 0.1947 - mse: 0.1947\n",
      "Epoch 89/150\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 90/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.1944 - mse: 0.1944\n",
      "Epoch 91/150\n",
      "91/91 [==============================] - 0s 610us/step - loss: 0.1944 - mse: 0.1944\n",
      "Epoch 92/150\n",
      "91/91 [==============================] - 0s 633us/step - loss: 0.1945 - mse: 0.1945\n",
      "Epoch 93/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 94/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 95/150\n",
      "91/91 [==============================] - 0s 618us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 96/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 97/150\n",
      "91/91 [==============================] - 0s 617us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 98/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 99/150\n",
      "91/91 [==============================] - 0s 649us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 100/150\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1938 - mse: 0.1938\n",
      "Epoch 101/150\n",
      "91/91 [==============================] - 0s 608us/step - loss: 0.1938 - mse: 0.1938\n",
      "Epoch 102/150\n",
      "91/91 [==============================] - 0s 633us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 103/150\n",
      "91/91 [==============================] - 0s 759us/step - loss: 0.1935 - mse: 0.1935\n",
      "Epoch 104/150\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.1936 - mse: 0.1936\n",
      "Epoch 105/150\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.1934 - mse: 0.1934\n",
      "Epoch 106/150\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.1933 - mse: 0.1933\n",
      "Epoch 107/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.1934 - mse: 0.1934\n",
      "Epoch 108/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 109/150\n",
      "91/91 [==============================] - 0s 625us/step - loss: 0.1931 - mse: 0.1931\n",
      "Epoch 110/150\n",
      "91/91 [==============================] - 0s 641us/step - loss: 0.1931 - mse: 0.1931\n",
      "Epoch 111/150\n",
      "91/91 [==============================] - 0s 625us/step - loss: 0.1930 - mse: 0.1930\n",
      "Epoch 112/150\n",
      "91/91 [==============================] - 0s 628us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 113/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 114/150\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 115/150\n",
      "91/91 [==============================] - 0s 715us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 116/150\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 117/150\n",
      "91/91 [==============================] - 0s 777us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 118/150\n",
      "91/91 [==============================] - 0s 710us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 119/150\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 120/150\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 121/150\n",
      "91/91 [==============================] - 0s 645us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 122/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 123/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 124/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 125/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 126/150\n",
      "91/91 [==============================] - 0s 630us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 127/150\n",
      "91/91 [==============================] - 0s 633us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 128/150\n",
      "91/91 [==============================] - 0s 631us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 129/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 130/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 131/150\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 132/150\n",
      "91/91 [==============================] - 0s 631us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 133/150\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 134/150\n",
      "91/91 [==============================] - 0s 614us/step - loss: 0.1916 - mse: 0.1916\n",
      "Epoch 135/150\n",
      "91/91 [==============================] - 0s 626us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 136/150\n",
      "91/91 [==============================] - 0s 626us/step - loss: 0.1916 - mse: 0.1916\n",
      "Epoch 137/150\n",
      "91/91 [==============================] - 0s 626us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 138/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 139/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 140/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 141/150\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 142/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 143/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 144/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 145/150\n",
      "91/91 [==============================] - 0s 625us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 146/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 147/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 148/150\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 149/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 150/150\n",
      "91/91 [==============================] - 0s 625us/step - loss: 0.1909 - mse: 0.1909\n",
      "23/23 [==============================] - 0s 574us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://445bf4e980854cbda56cef87ab9e9b62/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://445bf4e980854cbda56cef87ab9e9b62/assets\n",
      "2023-03-13 14:07:45.781597: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://0ac20d4195634f77ae42f747cc2e52e3: INVALID_ARGUMENT: ram://0ac20d4195634f77ae42f747cc2e52e3 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.6829 - mse: 0.6829\n",
      "Epoch 2/150\n",
      "91/91 [==============================] - 0s 653us/step - loss: 0.2906 - mse: 0.2906\n",
      "Epoch 3/150\n",
      "91/91 [==============================] - 0s 635us/step - loss: 0.2456 - mse: 0.2456\n",
      "Epoch 4/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.2354 - mse: 0.2354\n",
      "Epoch 5/150\n",
      "91/91 [==============================] - 0s 645us/step - loss: 0.2293 - mse: 0.2293\n",
      "Epoch 6/150\n",
      "91/91 [==============================] - 0s 633us/step - loss: 0.2247 - mse: 0.2247\n",
      "Epoch 7/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.2212 - mse: 0.2212\n",
      "Epoch 8/150\n",
      "91/91 [==============================] - 0s 658us/step - loss: 0.2182 - mse: 0.2182\n",
      "Epoch 9/150\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.2158 - mse: 0.2158\n",
      "Epoch 10/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.2137 - mse: 0.2137\n",
      "Epoch 11/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.2117 - mse: 0.2117\n",
      "Epoch 12/150\n",
      "91/91 [==============================] - 0s 617us/step - loss: 0.2104 - mse: 0.2104\n",
      "Epoch 13/150\n",
      "91/91 [==============================] - 0s 621us/step - loss: 0.2091 - mse: 0.2091\n",
      "Epoch 14/150\n",
      "91/91 [==============================] - 0s 618us/step - loss: 0.2078 - mse: 0.2078\n",
      "Epoch 15/150\n",
      "91/91 [==============================] - 0s 614us/step - loss: 0.2068 - mse: 0.2068\n",
      "Epoch 16/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.2058 - mse: 0.2058\n",
      "Epoch 17/150\n",
      "91/91 [==============================] - 0s 614us/step - loss: 0.2051 - mse: 0.2051\n",
      "Epoch 18/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.2044 - mse: 0.2044\n",
      "Epoch 19/150\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.2039 - mse: 0.2039\n",
      "Epoch 20/150\n",
      "91/91 [==============================] - 0s 623us/step - loss: 0.2033 - mse: 0.2033\n",
      "Epoch 21/150\n",
      "91/91 [==============================] - 0s 633us/step - loss: 0.2028 - mse: 0.2028\n",
      "Epoch 22/150\n",
      "91/91 [==============================] - 0s 642us/step - loss: 0.2023 - mse: 0.2023\n",
      "Epoch 23/150\n",
      "91/91 [==============================] - 0s 628us/step - loss: 0.2017 - mse: 0.2017\n",
      "Epoch 24/150\n",
      "91/91 [==============================] - 0s 628us/step - loss: 0.2013 - mse: 0.2013\n",
      "Epoch 25/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.2010 - mse: 0.2010\n",
      "Epoch 26/150\n",
      "91/91 [==============================] - 0s 621us/step - loss: 0.2007 - mse: 0.2007\n",
      "Epoch 27/150\n",
      "91/91 [==============================] - 0s 634us/step - loss: 0.2003 - mse: 0.2003\n",
      "Epoch 28/150\n",
      "91/91 [==============================] - 0s 621us/step - loss: 0.2002 - mse: 0.2002\n",
      "Epoch 29/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.1998 - mse: 0.1998\n",
      "Epoch 30/150\n",
      "91/91 [==============================] - 0s 633us/step - loss: 0.1991 - mse: 0.1991\n",
      "Epoch 31/150\n",
      "91/91 [==============================] - 0s 631us/step - loss: 0.1992 - mse: 0.1992\n",
      "Epoch 32/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1989 - mse: 0.1989\n",
      "Epoch 33/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.1988 - mse: 0.1988\n",
      "Epoch 34/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1985 - mse: 0.1985\n",
      "Epoch 35/150\n",
      "91/91 [==============================] - 0s 611us/step - loss: 0.1984 - mse: 0.1984\n",
      "Epoch 36/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1982 - mse: 0.1982\n",
      "Epoch 37/150\n",
      "91/91 [==============================] - 0s 638us/step - loss: 0.1980 - mse: 0.1980\n",
      "Epoch 38/150\n",
      "91/91 [==============================] - 0s 612us/step - loss: 0.1979 - mse: 0.1979\n",
      "Epoch 39/150\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.1976 - mse: 0.1976\n",
      "Epoch 40/150\n",
      "91/91 [==============================] - 0s 764us/step - loss: 0.1975 - mse: 0.1975\n",
      "Epoch 41/150\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.1974 - mse: 0.1974\n",
      "Epoch 42/150\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.1972 - mse: 0.1972\n",
      "Epoch 43/150\n",
      "91/91 [==============================] - 0s 631us/step - loss: 0.1971 - mse: 0.1971\n",
      "Epoch 44/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.1970 - mse: 0.1970\n",
      "Epoch 45/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 46/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 47/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 48/150\n",
      "91/91 [==============================] - 0s 617us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 49/150\n",
      "91/91 [==============================] - 0s 628us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 50/150\n",
      "91/91 [==============================] - 0s 638us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 51/150\n",
      "91/91 [==============================] - 0s 613us/step - loss: 0.1961 - mse: 0.1961\n",
      "Epoch 52/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.1961 - mse: 0.1961\n",
      "Epoch 53/150\n",
      "91/91 [==============================] - 0s 626us/step - loss: 0.1959 - mse: 0.1959\n",
      "Epoch 54/150\n",
      "91/91 [==============================] - 0s 629us/step - loss: 0.1959 - mse: 0.1959\n",
      "Epoch 55/150\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.1958 - mse: 0.1958\n",
      "Epoch 56/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 57/150\n",
      "91/91 [==============================] - 0s 628us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 58/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 59/150\n",
      "91/91 [==============================] - 0s 633us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 60/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1953 - mse: 0.1953\n",
      "Epoch 61/150\n",
      "91/91 [==============================] - 0s 618us/step - loss: 0.1952 - mse: 0.1952\n",
      "Epoch 62/150\n",
      "91/91 [==============================] - 0s 624us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 63/150\n",
      "91/91 [==============================] - 0s 625us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 64/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 65/150\n",
      "91/91 [==============================] - 0s 620us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 66/150\n",
      "91/91 [==============================] - 0s 615us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 67/150\n",
      "91/91 [==============================] - 0s 626us/step - loss: 0.1947 - mse: 0.1947\n",
      "Epoch 68/150\n",
      "91/91 [==============================] - 0s 621us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 69/150\n",
      "91/91 [==============================] - 0s 623us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 70/150\n",
      "91/91 [==============================] - 0s 634us/step - loss: 0.1944 - mse: 0.1944\n",
      "Epoch 71/150\n",
      "91/91 [==============================] - 0s 621us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 72/150\n",
      "91/91 [==============================] - 0s 619us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 73/150\n",
      "91/91 [==============================] - 0s 627us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 74/150\n",
      "91/91 [==============================] - 0s 619us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 75/150\n",
      "91/91 [==============================] - 0s 614us/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 76/150\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 77/150\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 78/150\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 79/150\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 80/150\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 81/150\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1936 - mse: 0.1936\n",
      "Epoch 82/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.1934 - mse: 0.1934\n",
      "Epoch 83/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1935 - mse: 0.1935\n",
      "Epoch 84/150\n",
      "91/91 [==============================] - 0s 637us/step - loss: 0.1933 - mse: 0.1933\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 651us/step - loss: 0.1933 - mse: 0.1933\n",
      "Epoch 86/150\n",
      "91/91 [==============================] - 0s 634us/step - loss: 0.1931 - mse: 0.1931\n",
      "Epoch 87/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1930 - mse: 0.1930\n",
      "Epoch 88/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1930 - mse: 0.1930\n",
      "Epoch 89/150\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 90/150\n",
      "91/91 [==============================] - 0s 799us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 91/150\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 92/150\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.1927 - mse: 0.1927\n",
      "Epoch 93/150\n",
      "91/91 [==============================] - 0s 721us/step - loss: 0.1927 - mse: 0.1927\n",
      "Epoch 94/150\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 95/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 96/150\n",
      "91/91 [==============================] - 0s 632us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 97/150\n",
      "91/91 [==============================] - 0s 623us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 98/150\n",
      "91/91 [==============================] - 0s 622us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 99/150\n",
      "91/91 [==============================] - 0s 640us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 100/150\n",
      "91/91 [==============================] - 0s 614us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 101/150\n",
      "91/91 [==============================] - 0s 625us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 102/150\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 103/150\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 104/150\n",
      "91/91 [==============================] - 0s 636us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 105/150\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 106/150\n",
      "91/91 [==============================] - 0s 717us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 107/150\n",
      "91/91 [==============================] - 0s 630us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 108/150\n",
      "91/91 [==============================] - 0s 631us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 109/150\n",
      "91/91 [==============================] - 0s 650us/step - loss: 0.1916 - mse: 0.1916\n",
      "Epoch 110/150\n",
      "91/91 [==============================] - 0s 623us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 111/150\n",
      "91/91 [==============================] - 0s 630us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 112/150\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 113/150\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 114/150\n",
      "91/91 [==============================] - 0s 628us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 115/150\n",
      "91/91 [==============================] - 0s 658us/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 116/150\n",
      "91/91 [==============================] - 0s 639us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 117/150\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 118/150\n",
      "91/91 [==============================] - 0s 662us/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 119/150\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 120/150\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 121/150\n",
      "91/91 [==============================] - 0s 656us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 122/150\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 123/150\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 124/150\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 125/150\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 126/150\n",
      "91/91 [==============================] - 0s 763us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 127/150\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 128/150\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1901 - mse: 0.1901\n",
      "Epoch 129/150\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 130/150\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1901 - mse: 0.1901\n",
      "Epoch 131/150\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1901 - mse: 0.1901\n",
      "Epoch 132/150\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 133/150\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1899 - mse: 0.1899\n",
      "Epoch 134/150\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1899 - mse: 0.1899\n",
      "Epoch 135/150\n",
      "91/91 [==============================] - 0s 641us/step - loss: 0.1899 - mse: 0.1899\n",
      "Epoch 136/150\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 137/150\n",
      "91/91 [==============================] - 0s 657us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 138/150\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 139/150\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1897 - mse: 0.1897\n",
      "Epoch 140/150\n",
      "91/91 [==============================] - 0s 643us/step - loss: 0.1895 - mse: 0.1895\n",
      "Epoch 141/150\n",
      "91/91 [==============================] - 0s 653us/step - loss: 0.1896 - mse: 0.1896\n",
      "Epoch 142/150\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.1894 - mse: 0.1894\n",
      "Epoch 143/150\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1893 - mse: 0.1893\n",
      "Epoch 144/150\n",
      "91/91 [==============================] - 0s 953us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 145/150\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 146/150\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.1893 - mse: 0.1893\n",
      "Epoch 147/150\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 148/150\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.1890 - mse: 0.1890\n",
      "Epoch 149/150\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 150/150\n",
      "91/91 [==============================] - 0s 709us/step - loss: 0.1891 - mse: 0.1891\n",
      "23/23 [==============================] - 0s 658us/step\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several mintes to run\n",
    "# Generate cross-validated predictions\n",
    "np.random.seed(123)\n",
    "cv_baseline_preds = cross_val_predict(keras_wrapper_1, X_train_all, y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the RMSE on train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4379141104386028"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE on train data (scaled)\n",
    "np.sqrt(mean_squared_error(y_train_scaled, cv_baseline_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the scaled predictions back to original scale \n",
    "- Calculate RMSE in the original units with `y_train` and `baseline_preds` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4004.8126509952417"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the predictions back to original scale\n",
    "baseline_preds = ss_y.inverse_transform(cv_baseline_preds)\n",
    "\n",
    "# RMSE on train data (original scale)\n",
    "np.sqrt(mean_squared_error(y_train, baseline_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intentionally Overfitting a Model\n",
    "\n",
    "Now that you've developed a baseline model, its time to intentionally overfit a model. To overfit a model, you can:\n",
    "* Add layers\n",
    "* Make the layers bigger\n",
    "* Increase the number of training epochs\n",
    "\n",
    "Again, be careful here. Think about the limitations of your resources, both in terms of your computers specs and how much time and patience you have to let the process run. Also keep in mind that you will then be regularizing these overfit models, meaning another round of experiments and more time and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that returns a compiled Keras model \n",
    "def create_bigger_model():\n",
    "    \n",
    "    # Initialize model\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(layers.Dense(20, activation='relu', input_shape=(n_features,)))\n",
    "\n",
    "    # Second hidden layer\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='SGD', \n",
    "                  loss='mse',  \n",
    "                  metrics=['mse']) \n",
    "    \n",
    "    # Return the compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the above function for use in cross-validation\n",
    "keras_wrapper_2 = KerasRegressor(create_bigger_model(), epochs=200, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d4c44f2829d34975abc7d83fa385791b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d4c44f2829d34975abc7d83fa385791b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:11:24.751644: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://26cc849c515648c3a0d3d6833b0859e8: INVALID_ARGUMENT: ram://26cc849c515648c3a0d3d6833b0859e8 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 847us/step - loss: 0.4844 - mse: 0.4844\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 800us/step - loss: 0.2722 - mse: 0.2722\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 815us/step - loss: 0.2453 - mse: 0.2453\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.2319 - mse: 0.2319\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.2235 - mse: 0.2235\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.2181 - mse: 0.2181\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 777us/step - loss: 0.2141 - mse: 0.2141\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.2092 - mse: 0.2092\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.2074 - mse: 0.2074\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.2060 - mse: 0.2060\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.2046 - mse: 0.2046\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 711us/step - loss: 0.2038 - mse: 0.2038\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2032 - mse: 0.2032\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2024 - mse: 0.2024\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 877us/step - loss: 0.2018 - mse: 0.2018\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 716us/step - loss: 0.2012 - mse: 0.2012\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2006 - mse: 0.2006\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 709us/step - loss: 0.2000 - mse: 0.2000\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.1998 - mse: 0.1998\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.1994 - mse: 0.1994\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 718us/step - loss: 0.1989 - mse: 0.1989\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.1982 - mse: 0.1982\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.1983 - mse: 0.1983\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.1979 - mse: 0.1979\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 709us/step - loss: 0.1977 - mse: 0.1977\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.1974 - mse: 0.1974\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 715us/step - loss: 0.1971 - mse: 0.1971\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1968 - mse: 0.1968\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.1959 - mse: 0.1959\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.1959 - mse: 0.1959\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.1958 - mse: 0.1958\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.1955 - mse: 0.1955\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 717us/step - loss: 0.1953 - mse: 0.1953\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 751us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.1945 - mse: 0.1945\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 812us/step - loss: 0.1931 - mse: 0.1931\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 818us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 796us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 711us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 723us/step - loss: 0.1927 - mse: 0.1927\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 716us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 709us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 709us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 778us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 914us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 770us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 785us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 794us/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 710us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 721us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.1897 - mse: 0.1897\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 794us/step - loss: 0.1897 - mse: 0.1897\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 715us/step - loss: 0.1895 - mse: 0.1895\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.1895 - mse: 0.1895\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 749us/step - loss: 0.1895 - mse: 0.1895\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1894 - mse: 0.1894\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1893 - mse: 0.1893\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 658us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1888 - mse: 0.1888\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1888 - mse: 0.1888\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1886 - mse: 0.1886\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1888 - mse: 0.1888\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1887 - mse: 0.1887\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1886 - mse: 0.1886\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1885 - mse: 0.1885\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 644us/step - loss: 0.1884 - mse: 0.1884\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.1884 - mse: 0.1884\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.1885 - mse: 0.1885\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.1882 - mse: 0.1882\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1882 - mse: 0.1882\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1881 - mse: 0.1881\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1878 - mse: 0.1878\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 664us/step - loss: 0.1875 - mse: 0.1875\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1876 - mse: 0.1876\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1875 - mse: 0.1875\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1873 - mse: 0.1873\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1873 - mse: 0.1873\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1871 - mse: 0.1871\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1870 - mse: 0.1870\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1871 - mse: 0.1871\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1870 - mse: 0.1870\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1869 - mse: 0.1869\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1869 - mse: 0.1869\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1869 - mse: 0.1869\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 650us/step - loss: 0.1867 - mse: 0.1867\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1868 - mse: 0.1868\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1868 - mse: 0.1868\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1866 - mse: 0.1866\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1865 - mse: 0.1865\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1867 - mse: 0.1867\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1866 - mse: 0.1866\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.1866 - mse: 0.1866\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.1865 - mse: 0.1865\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1865 - mse: 0.1865\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1865 - mse: 0.1865\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1863 - mse: 0.1863\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1864 - mse: 0.1864\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.1861 - mse: 0.1861\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1863 - mse: 0.1863\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1861 - mse: 0.1861\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1861 - mse: 0.1861\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1859 - mse: 0.1859\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1859 - mse: 0.1859\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1857 - mse: 0.1857\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1858 - mse: 0.1858\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1858 - mse: 0.1858\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.1857 - mse: 0.1857\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.1854 - mse: 0.1854\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1858 - mse: 0.1858\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 664us/step - loss: 0.1854 - mse: 0.1854\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1854 - mse: 0.1854\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1855 - mse: 0.1855\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1855 - mse: 0.1855\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 676us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1855 - mse: 0.1855\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 660us/step - loss: 0.1855 - mse: 0.1855\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1854 - mse: 0.1854\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1853 - mse: 0.1853\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.1853 - mse: 0.1853\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1853 - mse: 0.1853\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1853 - mse: 0.1853\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1852 - mse: 0.1852\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1852 - mse: 0.1852\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1853 - mse: 0.1853\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1852 - mse: 0.1852\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 790us/step - loss: 0.1852 - mse: 0.1852\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.1851 - mse: 0.1851\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 709us/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1851 - mse: 0.1851\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1849 - mse: 0.1849\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1849 - mse: 0.1849\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1848 - mse: 0.1848\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1848 - mse: 0.1848\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1849 - mse: 0.1849\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1847 - mse: 0.1847\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1845 - mse: 0.1845\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1849 - mse: 0.1849\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1847 - mse: 0.1847\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1847 - mse: 0.1847\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1845 - mse: 0.1845\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.1846 - mse: 0.1846\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1845 - mse: 0.1845\n",
      "23/23 [==============================] - 0s 589us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://0fbf9ede7274402793d3e6368d79072d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://0fbf9ede7274402793d3e6368d79072d/assets\n",
      "2023-03-13 14:11:38.654460: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://441aa5f9770942118fe05b1cfa5eedd6: INVALID_ARGUMENT: ram://441aa5f9770942118fe05b1cfa5eedd6 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "91/91 [==============================] - 0s 794us/step - loss: 0.4860 - mse: 0.4860\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2766 - mse: 0.2766\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.2509 - mse: 0.2509\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.2382 - mse: 0.2382\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.2308 - mse: 0.2308\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.2258 - mse: 0.2258\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.2224 - mse: 0.2224\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.2195 - mse: 0.2195\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.2170 - mse: 0.2170\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.2149 - mse: 0.2149\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 656us/step - loss: 0.2132 - mse: 0.2132\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.2119 - mse: 0.2119\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.2107 - mse: 0.2107\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.2097 - mse: 0.2097\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.2088 - mse: 0.2088\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.2080 - mse: 0.2080\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.2073 - mse: 0.2073\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.2066 - mse: 0.2066\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.2059 - mse: 0.2059\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.2054 - mse: 0.2054\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.2051 - mse: 0.2051\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.2047 - mse: 0.2047\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.2042 - mse: 0.2042\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.2039 - mse: 0.2039\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.2034 - mse: 0.2034\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.2033 - mse: 0.2033\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.2031 - mse: 0.2031\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.2027 - mse: 0.2027\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 664us/step - loss: 0.2025 - mse: 0.2025\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.2021 - mse: 0.2021\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.2019 - mse: 0.2019\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.2017 - mse: 0.2017\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.2015 - mse: 0.2015\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.2013 - mse: 0.2013\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 803us/step - loss: 0.2010 - mse: 0.2010\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.2008 - mse: 0.2008\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2006 - mse: 0.2006\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.2004 - mse: 0.2004\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.2004 - mse: 0.2004\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.2002 - mse: 0.2002\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.2000 - mse: 0.2000\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1997 - mse: 0.1997\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1995 - mse: 0.1995\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1995 - mse: 0.1995\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1994 - mse: 0.1994\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1991 - mse: 0.1991\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1991 - mse: 0.1991\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1989 - mse: 0.1989\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1988 - mse: 0.1988\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1986 - mse: 0.1986\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1987 - mse: 0.1987\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1982 - mse: 0.1982\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 664us/step - loss: 0.1983 - mse: 0.1983\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 654us/step - loss: 0.1981 - mse: 0.1981\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1980 - mse: 0.1980\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1978 - mse: 0.1978\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1978 - mse: 0.1978\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1976 - mse: 0.1976\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1976 - mse: 0.1976\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1972 - mse: 0.1972\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1974 - mse: 0.1974\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1972 - mse: 0.1972\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1971 - mse: 0.1971\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1966 - mse: 0.1966\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1962 - mse: 0.1962\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1960 - mse: 0.1960\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1960 - mse: 0.1960\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.1959 - mse: 0.1959\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1958 - mse: 0.1958\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1957 - mse: 0.1957\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 664us/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1953 - mse: 0.1953\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1953 - mse: 0.1953\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 674us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 656us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1947 - mse: 0.1947\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1947 - mse: 0.1947\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1945 - mse: 0.1945\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1945 - mse: 0.1945\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 664us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1938 - mse: 0.1938\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1938 - mse: 0.1938\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1934 - mse: 0.1934\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 714us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1934 - mse: 0.1934\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 653us/step - loss: 0.1934 - mse: 0.1934\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1934 - mse: 0.1934\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1931 - mse: 0.1931\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1930 - mse: 0.1930\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 658us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 648us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.1927 - mse: 0.1927\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 710us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 646us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1916 - mse: 0.1916\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1916 - mse: 0.1916\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 649us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 740us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 807us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 772us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 797us/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 711us/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 709us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 779us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 776us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 701us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1901 - mse: 0.1901\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1902 - mse: 0.1902\n",
      "23/23 [==============================] - 0s 653us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c4f837d896e74536962c490bcfb4541d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c4f837d896e74536962c490bcfb4541d/assets\n",
      "2023-03-13 14:11:52.534364: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://58d23adbe16740ee8680aab445255256: INVALID_ARGUMENT: ram://58d23adbe16740ee8680aab445255256 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "91/91 [==============================] - 0s 774us/step - loss: 0.4830 - mse: 0.4830\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.2717 - mse: 0.2717\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.2449 - mse: 0.2449\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 654us/step - loss: 0.2320 - mse: 0.2320\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 664us/step - loss: 0.2245 - mse: 0.2245\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.2197 - mse: 0.2197\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.2161 - mse: 0.2161\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.2130 - mse: 0.2130\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.2106 - mse: 0.2106\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.2086 - mse: 0.2086\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.2073 - mse: 0.2073\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.2062 - mse: 0.2062\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.2050 - mse: 0.2050\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 716us/step - loss: 0.2041 - mse: 0.2041\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2034 - mse: 0.2034\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.2027 - mse: 0.2027\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.2021 - mse: 0.2021\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 664us/step - loss: 0.2016 - mse: 0.2016\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.2011 - mse: 0.2011\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.2006 - mse: 0.2006\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.2003 - mse: 0.2003\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.1998 - mse: 0.1998\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1997 - mse: 0.1997\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 772us/step - loss: 0.1991 - mse: 0.1991\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1991 - mse: 0.1991\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 663us/step - loss: 0.1987 - mse: 0.1987\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1983 - mse: 0.1983\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1980 - mse: 0.1980\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1979 - mse: 0.1979\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1976 - mse: 0.1976\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1974 - mse: 0.1974\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1973 - mse: 0.1973\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1970 - mse: 0.1970\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1962 - mse: 0.1962\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1961 - mse: 0.1961\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1958 - mse: 0.1958\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1959 - mse: 0.1959\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 778us/step - loss: 0.1953 - mse: 0.1953\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 800us/step - loss: 0.1953 - mse: 0.1953\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1952 - mse: 0.1952\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1947 - mse: 0.1947\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 656us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1936 - mse: 0.1936\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1936 - mse: 0.1936\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1933 - mse: 0.1933\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1933 - mse: 0.1933\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1931 - mse: 0.1931\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1930 - mse: 0.1930\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 795us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 717us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1916 - mse: 0.1916\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 658us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 672us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1905 - mse: 0.1905\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 654us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 703us/step - loss: 0.1899 - mse: 0.1899\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1897 - mse: 0.1897\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1899 - mse: 0.1899\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1897 - mse: 0.1897\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1895 - mse: 0.1895\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 652us/step - loss: 0.1895 - mse: 0.1895\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1890 - mse: 0.1890\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1893 - mse: 0.1893\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1894 - mse: 0.1894\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 980us/step - loss: 0.1890 - mse: 0.1890\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1890 - mse: 0.1890\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1890 - mse: 0.1890\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1888 - mse: 0.1888\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1890 - mse: 0.1890\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1886 - mse: 0.1886\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1888 - mse: 0.1888\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1886 - mse: 0.1886\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1885 - mse: 0.1885\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1885 - mse: 0.1885\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1883 - mse: 0.1883\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.1883 - mse: 0.1883\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1885 - mse: 0.1885\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1883 - mse: 0.1883\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1881 - mse: 0.1881\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1882 - mse: 0.1882\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1882 - mse: 0.1882\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1881 - mse: 0.1881\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1878 - mse: 0.1878\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1878 - mse: 0.1878\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.1876 - mse: 0.1876\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1876 - mse: 0.1876\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1873 - mse: 0.1873\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1874 - mse: 0.1874\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1873 - mse: 0.1873\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.1873 - mse: 0.1873\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.1874 - mse: 0.1874\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.1871 - mse: 0.1871\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 809us/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 772us/step - loss: 0.1871 - mse: 0.1871\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1869 - mse: 0.1869\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1869 - mse: 0.1869\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1869 - mse: 0.1869\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1869 - mse: 0.1869\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1869 - mse: 0.1869\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.1867 - mse: 0.1867\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1868 - mse: 0.1868\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1868 - mse: 0.1868\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1866 - mse: 0.1866\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1865 - mse: 0.1865\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1866 - mse: 0.1866\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1868 - mse: 0.1868\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 688us/step - loss: 0.1866 - mse: 0.1866\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1866 - mse: 0.1866\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1865 - mse: 0.1865\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1866 - mse: 0.1866\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1864 - mse: 0.1864\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1864 - mse: 0.1864\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1863 - mse: 0.1863\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1865 - mse: 0.1865\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1865 - mse: 0.1865\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1863 - mse: 0.1863\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1861 - mse: 0.1861\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1861 - mse: 0.1861\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1863 - mse: 0.1863\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1861 - mse: 0.1861\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1861 - mse: 0.1861\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1860 - mse: 0.1860\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1860 - mse: 0.1860\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1859 - mse: 0.1859\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 715us/step - loss: 0.1859 - mse: 0.1859\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.1860 - mse: 0.1860\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1860 - mse: 0.1860\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1858 - mse: 0.1858\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1858 - mse: 0.1858\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1858 - mse: 0.1858\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 662us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1858 - mse: 0.1858\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1858 - mse: 0.1858\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1856 - mse: 0.1856\n",
      "23/23 [==============================] - 0s 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://308d8b867c044fa8a26da774a1e7caa1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://308d8b867c044fa8a26da774a1e7caa1/assets\n",
      "2023-03-13 14:12:06.060112: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://3f7cd49c7afd446e97fe85e411328cce: INVALID_ARGUMENT: ram://3f7cd49c7afd446e97fe85e411328cce is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.4841 - mse: 0.4841\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.2736 - mse: 0.2736\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.2471 - mse: 0.2471\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.2342 - mse: 0.2342\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 719us/step - loss: 0.2263 - mse: 0.2263\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2207 - mse: 0.2207\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.2167 - mse: 0.2167\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.2138 - mse: 0.2138\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.2117 - mse: 0.2117\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.2097 - mse: 0.2097\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2085 - mse: 0.2085\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2071 - mse: 0.2071\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.2063 - mse: 0.2063\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.2055 - mse: 0.2055\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.2049 - mse: 0.2049\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2043 - mse: 0.2043\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 703us/step - loss: 0.2035 - mse: 0.2035\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.2031 - mse: 0.2031\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.2027 - mse: 0.2027\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.2023 - mse: 0.2023\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.2019 - mse: 0.2019\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.2015 - mse: 0.2015\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 714us/step - loss: 0.2009 - mse: 0.2009\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.2008 - mse: 0.2008\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.2004 - mse: 0.2004\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.2003 - mse: 0.2003\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1999 - mse: 0.1999\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1998 - mse: 0.1998\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 979us/step - loss: 0.1994 - mse: 0.1994\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1992 - mse: 0.1992\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1990 - mse: 0.1990\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1988 - mse: 0.1988\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1986 - mse: 0.1986\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1984 - mse: 0.1984\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.1984 - mse: 0.1984\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1982 - mse: 0.1982\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1980 - mse: 0.1980\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1978 - mse: 0.1978\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1977 - mse: 0.1977\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1976 - mse: 0.1976\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1973 - mse: 0.1973\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1971 - mse: 0.1971\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1971 - mse: 0.1971\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1968 - mse: 0.1968\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 701us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1963 - mse: 0.1963\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1962 - mse: 0.1962\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1961 - mse: 0.1961\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1960 - mse: 0.1960\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1959 - mse: 0.1959\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1957 - mse: 0.1957\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1955 - mse: 0.1955\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1953 - mse: 0.1953\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 714us/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 805us/step - loss: 0.1947 - mse: 0.1947\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.1945 - mse: 0.1945\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 766us/step - loss: 0.1945 - mse: 0.1945\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 763us/step - loss: 0.1944 - mse: 0.1944\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.1943 - mse: 0.1943\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 722us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1937 - mse: 0.1937\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1936 - mse: 0.1936\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1934 - mse: 0.1934\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1935 - mse: 0.1935\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1933 - mse: 0.1933\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 785us/step - loss: 0.1933 - mse: 0.1933\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1933 - mse: 0.1933\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1930 - mse: 0.1930\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 715us/step - loss: 0.1928 - mse: 0.1928\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 738us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 721us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 656us/step - loss: 0.1922 - mse: 0.1922\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1918 - mse: 0.1918\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 667us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1916 - mse: 0.1916\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 658us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.1915 - mse: 0.1915\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 722us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 710us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1914 - mse: 0.1914\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1912 - mse: 0.1912\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 674us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 800us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 770us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 715us/step - loss: 0.1901 - mse: 0.1901\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 805us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.1899 - mse: 0.1899\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1897 - mse: 0.1897\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 666us/step - loss: 0.1897 - mse: 0.1897\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1896 - mse: 0.1896\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1896 - mse: 0.1896\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 759us/step - loss: 0.1896 - mse: 0.1896\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.1895 - mse: 0.1895\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 722us/step - loss: 0.1895 - mse: 0.1895\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1894 - mse: 0.1894\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1893 - mse: 0.1893\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.1893 - mse: 0.1893\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1894 - mse: 0.1894\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.1890 - mse: 0.1890\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 701us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 722us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.1888 - mse: 0.1888\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1886 - mse: 0.1886\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1888 - mse: 0.1888\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.1888 - mse: 0.1888\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1886 - mse: 0.1886\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1887 - mse: 0.1887\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1883 - mse: 0.1883\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.1887 - mse: 0.1887\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.1885 - mse: 0.1885\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.1885 - mse: 0.1885\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.1886 - mse: 0.1886\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 795us/step - loss: 0.1884 - mse: 0.1884\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.1885 - mse: 0.1885\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.1884 - mse: 0.1884\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 706us/step - loss: 0.1883 - mse: 0.1883\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 710us/step - loss: 0.1882 - mse: 0.1882\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.1882 - mse: 0.1882\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 717us/step - loss: 0.1883 - mse: 0.1883\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1882 - mse: 0.1882\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1883 - mse: 0.1883\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.1878 - mse: 0.1878\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1878 - mse: 0.1878\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 703us/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 710us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1878 - mse: 0.1878\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.1876 - mse: 0.1876\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 709us/step - loss: 0.1876 - mse: 0.1876\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.1875 - mse: 0.1875\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1876 - mse: 0.1876\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.1876 - mse: 0.1876\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1876 - mse: 0.1876\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1874 - mse: 0.1874\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1875 - mse: 0.1875\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.1875 - mse: 0.1875\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.1875 - mse: 0.1875\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1875 - mse: 0.1875\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1870 - mse: 0.1870\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1873 - mse: 0.1873\n",
      "23/23 [==============================] - 0s 738us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://57d0f66f46bf45f18d09d0625d32d6cf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://57d0f66f46bf45f18d09d0625d32d6cf/assets\n",
      "2023-03-13 14:12:19.903527: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://2118c1c726884b9b91dfdc49068bd87f: INVALID_ARGUMENT: ram://2118c1c726884b9b91dfdc49068bd87f is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "91/91 [==============================] - 0s 781us/step - loss: 0.4817 - mse: 0.4817\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.2711 - mse: 0.2711\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.2452 - mse: 0.2452\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.2324 - mse: 0.2324\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.2247 - mse: 0.2247\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.2196 - mse: 0.2196\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 776us/step - loss: 0.2158 - mse: 0.2158\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.2128 - mse: 0.2128\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.2103 - mse: 0.2103\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 651us/step - loss: 0.2086 - mse: 0.2086\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.2069 - mse: 0.2069\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.2059 - mse: 0.2059\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.2049 - mse: 0.2049\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.2039 - mse: 0.2039\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2032 - mse: 0.2032\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.2024 - mse: 0.2024\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.2020 - mse: 0.2020\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.2012 - mse: 0.2012\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.2009 - mse: 0.2009\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.2004 - mse: 0.2004\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.2000 - mse: 0.2000\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1999 - mse: 0.1999\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1995 - mse: 0.1995\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1991 - mse: 0.1991\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1988 - mse: 0.1988\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1987 - mse: 0.1987\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1984 - mse: 0.1984\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1980 - mse: 0.1980\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1978 - mse: 0.1978\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1975 - mse: 0.1975\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1973 - mse: 0.1973\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1971 - mse: 0.1971\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1968 - mse: 0.1968\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1964 - mse: 0.1964\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1962 - mse: 0.1962\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 633us/step - loss: 0.1960 - mse: 0.1960\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1960 - mse: 0.1960\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1957 - mse: 0.1957\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1955 - mse: 0.1955\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1951 - mse: 0.1951\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.1952 - mse: 0.1952\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 695us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1949 - mse: 0.1949\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.1946 - mse: 0.1946\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1945 - mse: 0.1945\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1944 - mse: 0.1944\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 701us/step - loss: 0.1944 - mse: 0.1944\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1941 - mse: 0.1941\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 714us/step - loss: 0.1939 - mse: 0.1939\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 714us/step - loss: 0.1935 - mse: 0.1935\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1935 - mse: 0.1935\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1932 - mse: 0.1932\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1930 - mse: 0.1930\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 706us/step - loss: 0.1930 - mse: 0.1930\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1929 - mse: 0.1929\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 679us/step - loss: 0.1926 - mse: 0.1926\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.1924 - mse: 0.1924\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1925 - mse: 0.1925\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.1923 - mse: 0.1923\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1920 - mse: 0.1920\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.1921 - mse: 0.1921\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.1919 - mse: 0.1919\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1916 - mse: 0.1916\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1913 - mse: 0.1913\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1911 - mse: 0.1911\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 705us/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1907 - mse: 0.1907\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 664us/step - loss: 0.1906 - mse: 0.1906\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1904 - mse: 0.1904\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 703us/step - loss: 0.1903 - mse: 0.1903\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 662us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 672us/step - loss: 0.1900 - mse: 0.1900\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1898 - mse: 0.1898\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1895 - mse: 0.1895\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 697us/step - loss: 0.1895 - mse: 0.1895\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1896 - mse: 0.1896\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1894 - mse: 0.1894\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1894 - mse: 0.1894\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.1893 - mse: 0.1893\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 676us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 686us/step - loss: 0.1892 - mse: 0.1892\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 661us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1891 - mse: 0.1891\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 775us/step - loss: 0.1888 - mse: 0.1888\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 670us/step - loss: 0.1887 - mse: 0.1887\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1887 - mse: 0.1887\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1885 - mse: 0.1885\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1884 - mse: 0.1884\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 675us/step - loss: 0.1884 - mse: 0.1884\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 694us/step - loss: 0.1884 - mse: 0.1884\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1883 - mse: 0.1883\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1883 - mse: 0.1883\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1882 - mse: 0.1882\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1881 - mse: 0.1881\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.1881 - mse: 0.1881\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.1879 - mse: 0.1879\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 678us/step - loss: 0.1878 - mse: 0.1878\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 722us/step - loss: 0.1878 - mse: 0.1878\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.1878 - mse: 0.1878\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 703us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1876 - mse: 0.1876\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.1877 - mse: 0.1877\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.1876 - mse: 0.1876\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 766us/step - loss: 0.1874 - mse: 0.1874\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1874 - mse: 0.1874\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1874 - mse: 0.1874\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.1873 - mse: 0.1873\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.1870 - mse: 0.1870\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.1873 - mse: 0.1873\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 701us/step - loss: 0.1870 - mse: 0.1870\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 673us/step - loss: 0.1870 - mse: 0.1870\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 647us/step - loss: 0.1867 - mse: 0.1867\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1870 - mse: 0.1870\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.1870 - mse: 0.1870\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.1868 - mse: 0.1868\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 777us/step - loss: 0.1867 - mse: 0.1867\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.1867 - mse: 0.1867\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1867 - mse: 0.1867\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.1867 - mse: 0.1867\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 702us/step - loss: 0.1866 - mse: 0.1866\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.1866 - mse: 0.1866\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 682us/step - loss: 0.1863 - mse: 0.1863\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1865 - mse: 0.1865\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1863 - mse: 0.1863\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1863 - mse: 0.1863\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.1864 - mse: 0.1864\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1861 - mse: 0.1861\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 726us/step - loss: 0.1863 - mse: 0.1863\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 723us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 706us/step - loss: 0.1860 - mse: 0.1860\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.1859 - mse: 0.1859\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 706us/step - loss: 0.1861 - mse: 0.1861\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.1859 - mse: 0.1859\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 715us/step - loss: 0.1858 - mse: 0.1858\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 719us/step - loss: 0.1859 - mse: 0.1859\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.1859 - mse: 0.1859\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 707us/step - loss: 0.1860 - mse: 0.1860\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1857 - mse: 0.1857\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.1857 - mse: 0.1857\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 794us/step - loss: 0.1858 - mse: 0.1858\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 680us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.1855 - mse: 0.1855\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1855 - mse: 0.1855\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1855 - mse: 0.1855\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 677us/step - loss: 0.1854 - mse: 0.1854\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1853 - mse: 0.1853\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 665us/step - loss: 0.1854 - mse: 0.1854\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 671us/step - loss: 0.1853 - mse: 0.1853\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.1853 - mse: 0.1853\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.1852 - mse: 0.1852\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 719us/step - loss: 0.1852 - mse: 0.1852\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.1851 - mse: 0.1851\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1852 - mse: 0.1852\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 669us/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 655us/step - loss: 0.1848 - mse: 0.1848\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.1851 - mse: 0.1851\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 716us/step - loss: 0.1851 - mse: 0.1851\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 711us/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.1848 - mse: 0.1848\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 668us/step - loss: 0.1849 - mse: 0.1849\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.1848 - mse: 0.1848\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1847 - mse: 0.1847\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.1847 - mse: 0.1847\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 701us/step - loss: 0.1846 - mse: 0.1846\n",
      "23/23 [==============================] - 0s 625us/step\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several mintes to run\n",
    "# Generate cross-validated predictions\n",
    "np.random.seed(123)\n",
    "cv_bigger_model_preds = cross_val_predict(keras_wrapper_2, X_train_all, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43519830187457814"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE on train data (scaled)\n",
    "np.sqrt(mean_squared_error(y_train_scaled, cv_bigger_model_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizing the Model to Achieve Balance  \n",
    "\n",
    "Now that you have a powerful model (albeit an overfit one), we can now increase the generalization of the model by using some of the regularization techniques we discussed. Some options you have to try include:  \n",
    "* Adding dropout\n",
    "* Adding L1/L2 regularization\n",
    "* Altering the layer architecture (add or remove layers similar to above)  \n",
    "\n",
    "This process will be constrained by time and resources. Be sure to test at least two different methodologies, such as dropout and L2 regularization. If you have the time, feel free to continue experimenting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that returns a compiled Keras model \n",
    "def create_regularized_model():\n",
    "    \n",
    "    # Initialize model\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(layers.Dense(20, activation='relu', input_shape=(n_features,)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Second hidden layer\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='SGD', \n",
    "                  loss='mse',  \n",
    "                  metrics=['mse']) \n",
    "    \n",
    "    # Return the compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the above function for use in cross-validation\n",
    "keras_wrapper_3 = KerasRegressor(create_regularized_model(), epochs=200, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b0d30f0a255545f497ffd6f0768c2c9d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b0d30f0a255545f497ffd6f0768c2c9d/assets\n",
      "2023-03-13 14:14:22.096332: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://aafe9825afc7414fa7416c383b8c3327: INVALID_ARGUMENT: ram://aafe9825afc7414fa7416c383b8c3327 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.6097 - mse: 0.6097\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 886us/step - loss: 0.4719 - mse: 0.4719\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 879us/step - loss: 0.4356 - mse: 0.4356\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 895us/step - loss: 0.4169 - mse: 0.4169\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.3926 - mse: 0.3926\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.3884 - mse: 0.3884\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 887us/step - loss: 0.3750 - mse: 0.3750\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.3704 - mse: 0.3704\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 763us/step - loss: 0.3632 - mse: 0.3632\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 790us/step - loss: 0.3578 - mse: 0.3578\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 808us/step - loss: 0.3527 - mse: 0.3527\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 858us/step - loss: 0.3511 - mse: 0.3511\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.3505 - mse: 0.3505\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.3400 - mse: 0.3400\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 789us/step - loss: 0.3399 - mse: 0.3399\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.3435 - mse: 0.3435\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 812us/step - loss: 0.3343 - mse: 0.3343\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 792us/step - loss: 0.3349 - mse: 0.3349\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 786us/step - loss: 0.3418 - mse: 0.3418\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.3388 - mse: 0.3388\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 789us/step - loss: 0.3264 - mse: 0.3264\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 801us/step - loss: 0.3247 - mse: 0.3247\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 796us/step - loss: 0.3217 - mse: 0.3217\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 889us/step - loss: 0.3262 - mse: 0.3262\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3212 - mse: 0.3212\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 995us/step - loss: 0.3166 - mse: 0.3166\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3184 - mse: 0.3184\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 938us/step - loss: 0.3185 - mse: 0.3185\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3172 - mse: 0.3172\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 796us/step - loss: 0.3165 - mse: 0.3165\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 800us/step - loss: 0.3147 - mse: 0.3147\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.3144 - mse: 0.3144\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.3169 - mse: 0.3169\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.3100 - mse: 0.3100\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 782us/step - loss: 0.3075 - mse: 0.3075\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.3088 - mse: 0.3088\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 769us/step - loss: 0.3105 - mse: 0.3105\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 783us/step - loss: 0.3029 - mse: 0.3029\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.3105 - mse: 0.3105\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 796us/step - loss: 0.3098 - mse: 0.3098\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 789us/step - loss: 0.3018 - mse: 0.3018\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 970us/step - loss: 0.3091 - mse: 0.3091\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2992 - mse: 0.2992\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 901us/step - loss: 0.3079 - mse: 0.3079\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 814us/step - loss: 0.3027 - mse: 0.3027\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 815us/step - loss: 0.3057 - mse: 0.3057\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 858us/step - loss: 0.3091 - mse: 0.3091\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.3011 - mse: 0.3011\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 983us/step - loss: 0.3040 - mse: 0.3040\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 881us/step - loss: 0.3060 - mse: 0.3060\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.2975 - mse: 0.2975\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.3018 - mse: 0.3018\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 798us/step - loss: 0.2989 - mse: 0.2989\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 878us/step - loss: 0.3024 - mse: 0.3024\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 878us/step - loss: 0.3012 - mse: 0.3012\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 803us/step - loss: 0.3030 - mse: 0.3030\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 759us/step - loss: 0.2969 - mse: 0.2969\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.3043 - mse: 0.3043\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.2994 - mse: 0.2994\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 778us/step - loss: 0.2982 - mse: 0.2982\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 857us/step - loss: 0.3034 - mse: 0.3034\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 786us/step - loss: 0.3029 - mse: 0.3029\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 803us/step - loss: 0.3014 - mse: 0.3014\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2967 - mse: 0.2967\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 810us/step - loss: 0.2977 - mse: 0.2977\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 781us/step - loss: 0.3015 - mse: 0.3015\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 801us/step - loss: 0.2969 - mse: 0.2969\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 811us/step - loss: 0.3058 - mse: 0.3058\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 781us/step - loss: 0.3038 - mse: 0.3038\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 815us/step - loss: 0.3030 - mse: 0.3030\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 792us/step - loss: 0.2991 - mse: 0.2991\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 813us/step - loss: 0.2939 - mse: 0.2939\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 785us/step - loss: 0.2930 - mse: 0.2930\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 810us/step - loss: 0.2894 - mse: 0.2894\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 771us/step - loss: 0.2940 - mse: 0.2940\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2970 - mse: 0.2970\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.2972 - mse: 0.2972\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 803us/step - loss: 0.3000 - mse: 0.3000\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2993 - mse: 0.2993\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 798us/step - loss: 0.2956 - mse: 0.2956\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2989 - mse: 0.2989\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 786us/step - loss: 0.2946 - mse: 0.2946\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 894us/step - loss: 0.2919 - mse: 0.2919\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 818us/step - loss: 0.2976 - mse: 0.2976\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 814us/step - loss: 0.2937 - mse: 0.2937\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.2941 - mse: 0.2941\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 777us/step - loss: 0.2977 - mse: 0.2977\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.3011 - mse: 0.3011\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2927 - mse: 0.2927\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2931 - mse: 0.2931\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2892 - mse: 0.2892\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.2918 - mse: 0.2918\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 726us/step - loss: 0.2887 - mse: 0.2887\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.2949 - mse: 0.2949\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2931 - mse: 0.2931\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.2951 - mse: 0.2951\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.2860 - mse: 0.2860\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2938 - mse: 0.2938\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.2901 - mse: 0.2901\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 764us/step - loss: 0.2913 - mse: 0.2913\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.2910 - mse: 0.2910\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.2977 - mse: 0.2977\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2923 - mse: 0.2923\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.2928 - mse: 0.2928\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.2952 - mse: 0.2952\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.2950 - mse: 0.2950\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.2879 - mse: 0.2879\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2874 - mse: 0.2874\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 794us/step - loss: 0.2878 - mse: 0.2878\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.2955 - mse: 0.2955\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.2915 - mse: 0.2915\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2876 - mse: 0.2876\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2902 - mse: 0.2902\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2879 - mse: 0.2879\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2904 - mse: 0.2904\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 766us/step - loss: 0.2924 - mse: 0.2924\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2910 - mse: 0.2910\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.2902 - mse: 0.2902\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 763us/step - loss: 0.2933 - mse: 0.2933\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.2886 - mse: 0.2886\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.2904 - mse: 0.2904\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.2876 - mse: 0.2876\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.2928 - mse: 0.2928\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.2869 - mse: 0.2869\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 769us/step - loss: 0.2937 - mse: 0.2937\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 723us/step - loss: 0.2904 - mse: 0.2904\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.2874 - mse: 0.2874\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2944 - mse: 0.2944\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2882 - mse: 0.2882\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.2873 - mse: 0.2873\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.2893 - mse: 0.2893\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2840 - mse: 0.2840\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.2920 - mse: 0.2920\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.2902 - mse: 0.2902\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.2849 - mse: 0.2849\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2902 - mse: 0.2902\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2865 - mse: 0.2865\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.2892 - mse: 0.2892\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2874 - mse: 0.2874\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 769us/step - loss: 0.2940 - mse: 0.2940\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2897 - mse: 0.2897\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.2845 - mse: 0.2845\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2888 - mse: 0.2888\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 767us/step - loss: 0.2907 - mse: 0.2907\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2913 - mse: 0.2913\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2904 - mse: 0.2904\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.2823 - mse: 0.2823\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 776us/step - loss: 0.2903 - mse: 0.2903\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.2850 - mse: 0.2850\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 769us/step - loss: 0.2934 - mse: 0.2934\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2946 - mse: 0.2946\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 816us/step - loss: 0.2925 - mse: 0.2925\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 769us/step - loss: 0.2882 - mse: 0.2882\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.2879 - mse: 0.2879\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.2865 - mse: 0.2865\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 764us/step - loss: 0.2881 - mse: 0.2881\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.2809 - mse: 0.2809\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2824 - mse: 0.2824\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.2882 - mse: 0.2882\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2869 - mse: 0.2869\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.2865 - mse: 0.2865\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.2857 - mse: 0.2857\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.2857 - mse: 0.2857\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.2870 - mse: 0.2870\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2901 - mse: 0.2901\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 718us/step - loss: 0.2871 - mse: 0.2871\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 788us/step - loss: 0.2900 - mse: 0.2900\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 737us/step - loss: 0.2906 - mse: 0.2906\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2870 - mse: 0.2870\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 794us/step - loss: 0.2882 - mse: 0.2882\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2880 - mse: 0.2880\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.2853 - mse: 0.2853\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.2864 - mse: 0.2864\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.2819 - mse: 0.2819\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.2902 - mse: 0.2902\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.2872 - mse: 0.2872\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.2859 - mse: 0.2859\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.2817 - mse: 0.2817\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2845 - mse: 0.2845\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.2854 - mse: 0.2854\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.2863 - mse: 0.2863\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.2855 - mse: 0.2855\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.2797 - mse: 0.2797\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.2913 - mse: 0.2913\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.2843 - mse: 0.2843\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.2804 - mse: 0.2804\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.2860 - mse: 0.2860\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.2910 - mse: 0.2910\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.2798 - mse: 0.2798\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2865 - mse: 0.2865\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.2894 - mse: 0.2894\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.2881 - mse: 0.2881\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.2857 - mse: 0.2857\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 767us/step - loss: 0.2798 - mse: 0.2798\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.2834 - mse: 0.2834\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.2840 - mse: 0.2840\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.2814 - mse: 0.2814\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2845 - mse: 0.2845\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 803us/step - loss: 0.2880 - mse: 0.2880\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.2870 - mse: 0.2870\n",
      "23/23 [==============================] - 0s 586us/step\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7da66b514fbf4a01ba8173ac1d89f6f8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7da66b514fbf4a01ba8173ac1d89f6f8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:14:37.992929: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://f9ccced021ed4a929f9fba4e6c954803: INVALID_ARGUMENT: ram://f9ccced021ed4a929f9fba4e6c954803 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 832us/step - loss: 0.6269 - mse: 0.6269\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 782us/step - loss: 0.4863 - mse: 0.4863\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 784us/step - loss: 0.4422 - mse: 0.4422\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.4064 - mse: 0.4064\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 771us/step - loss: 0.3965 - mse: 0.3965\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.3823 - mse: 0.3823\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 767us/step - loss: 0.3784 - mse: 0.3784\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.3761 - mse: 0.3761\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 792us/step - loss: 0.3576 - mse: 0.3576\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 810us/step - loss: 0.3695 - mse: 0.3695\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.3639 - mse: 0.3639\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.3582 - mse: 0.3582\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.3462 - mse: 0.3462\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.3454 - mse: 0.3454\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 783us/step - loss: 0.3478 - mse: 0.3478\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 797us/step - loss: 0.3472 - mse: 0.3472\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 778us/step - loss: 0.3457 - mse: 0.3457\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.3487 - mse: 0.3487\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.3394 - mse: 0.3394\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 776us/step - loss: 0.3438 - mse: 0.3438\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.3482 - mse: 0.3482\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 909us/step - loss: 0.3338 - mse: 0.3338\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 799us/step - loss: 0.3335 - mse: 0.3335\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 764us/step - loss: 0.3281 - mse: 0.3281\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.3264 - mse: 0.3264\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.3192 - mse: 0.3192\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.3287 - mse: 0.3287\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.3260 - mse: 0.3260\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.3262 - mse: 0.3262\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.3090 - mse: 0.3090\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.3257 - mse: 0.3257\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.3194 - mse: 0.3194\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.3216 - mse: 0.3216\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.3176 - mse: 0.3176\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 810us/step - loss: 0.3191 - mse: 0.3191\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 791us/step - loss: 0.3184 - mse: 0.3184\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 808us/step - loss: 0.3184 - mse: 0.3184\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 798us/step - loss: 0.3068 - mse: 0.3068\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 800us/step - loss: 0.3125 - mse: 0.3125\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.3127 - mse: 0.3127\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.3095 - mse: 0.3095\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.3073 - mse: 0.3073\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 791us/step - loss: 0.3129 - mse: 0.3129\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 785us/step - loss: 0.3098 - mse: 0.3098\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 787us/step - loss: 0.3141 - mse: 0.3141\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3031 - mse: 0.3031\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.3079 - mse: 0.3079\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.3068 - mse: 0.3068\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 778us/step - loss: 0.3081 - mse: 0.3081\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.3090 - mse: 0.3090\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.3081 - mse: 0.3081\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 723us/step - loss: 0.3056 - mse: 0.3056\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.3044 - mse: 0.3044\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 759us/step - loss: 0.3064 - mse: 0.3064\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.3048 - mse: 0.3048\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 726us/step - loss: 0.3064 - mse: 0.3064\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.3047 - mse: 0.3047\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 722us/step - loss: 0.3034 - mse: 0.3034\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.3056 - mse: 0.3056\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2961 - mse: 0.2961\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2999 - mse: 0.2999\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.3113 - mse: 0.3113\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.3070 - mse: 0.3070\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.3119 - mse: 0.3119\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.3013 - mse: 0.3013\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.3076 - mse: 0.3076\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 767us/step - loss: 0.3051 - mse: 0.3051\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2989 - mse: 0.2989\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2979 - mse: 0.2979\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2981 - mse: 0.2981\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.3013 - mse: 0.3013\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.3061 - mse: 0.3061\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.3022 - mse: 0.3022\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.3003 - mse: 0.3003\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.3022 - mse: 0.3022\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.2979 - mse: 0.2979\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.2929 - mse: 0.2929\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.3003 - mse: 0.3003\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 798us/step - loss: 0.2998 - mse: 0.2998\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.3024 - mse: 0.3024\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.2960 - mse: 0.2960\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 993us/step - loss: 0.2965 - mse: 0.2965\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 797us/step - loss: 0.2951 - mse: 0.2951\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 920us/step - loss: 0.2996 - mse: 0.2996\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 800us/step - loss: 0.2975 - mse: 0.2975\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 763us/step - loss: 0.2994 - mse: 0.2994\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2983 - mse: 0.2983\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2954 - mse: 0.2954\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.2991 - mse: 0.2991\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 769us/step - loss: 0.3052 - mse: 0.3052\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.3019 - mse: 0.3019\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 726us/step - loss: 0.2985 - mse: 0.2985\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 781us/step - loss: 0.3042 - mse: 0.3042\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.3013 - mse: 0.3013\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2928 - mse: 0.2928\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.3031 - mse: 0.3031\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2953 - mse: 0.2953\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 812us/step - loss: 0.2954 - mse: 0.2954\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 751us/step - loss: 0.2998 - mse: 0.2998\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2901 - mse: 0.2901\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.3009 - mse: 0.3009\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 722us/step - loss: 0.2939 - mse: 0.2939\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 788us/step - loss: 0.2918 - mse: 0.2918\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.2950 - mse: 0.2950\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 784us/step - loss: 0.2981 - mse: 0.2981\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 777us/step - loss: 0.2986 - mse: 0.2986\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2928 - mse: 0.2928\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 781us/step - loss: 0.3010 - mse: 0.3010\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 764us/step - loss: 0.2943 - mse: 0.2943\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 717us/step - loss: 0.2974 - mse: 0.2974\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.2960 - mse: 0.2960\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.2950 - mse: 0.2950\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 770us/step - loss: 0.2937 - mse: 0.2937\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 800us/step - loss: 0.2944 - mse: 0.2944\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2964 - mse: 0.2964\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 763us/step - loss: 0.2884 - mse: 0.2884\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2935 - mse: 0.2935\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 766us/step - loss: 0.2919 - mse: 0.2919\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.2885 - mse: 0.2885\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.2944 - mse: 0.2944\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2867 - mse: 0.2867\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2907 - mse: 0.2907\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2879 - mse: 0.2879\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 767us/step - loss: 0.2943 - mse: 0.2943\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2943 - mse: 0.2943\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 718us/step - loss: 0.2928 - mse: 0.2928\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.2937 - mse: 0.2937\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2906 - mse: 0.2906\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2918 - mse: 0.2918\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 767us/step - loss: 0.2960 - mse: 0.2960\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 775us/step - loss: 0.3035 - mse: 0.3035\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2917 - mse: 0.2917\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 779us/step - loss: 0.2899 - mse: 0.2899\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2922 - mse: 0.2922\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2897 - mse: 0.2897\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.3002 - mse: 0.3002\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.2894 - mse: 0.2894\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2948 - mse: 0.2948\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 791us/step - loss: 0.2896 - mse: 0.2896\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 751us/step - loss: 0.2876 - mse: 0.2876\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 726us/step - loss: 0.2909 - mse: 0.2909\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.2896 - mse: 0.2896\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2961 - mse: 0.2961\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2901 - mse: 0.2901\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.2889 - mse: 0.2889\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.2874 - mse: 0.2874\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2912 - mse: 0.2912\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2864 - mse: 0.2864\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 726us/step - loss: 0.2925 - mse: 0.2925\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 726us/step - loss: 0.2911 - mse: 0.2911\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.2898 - mse: 0.2898\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.2885 - mse: 0.2885\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2916 - mse: 0.2916\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 723us/step - loss: 0.2909 - mse: 0.2909\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.2889 - mse: 0.2889\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.2923 - mse: 0.2923\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.2854 - mse: 0.2854\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 723us/step - loss: 0.2837 - mse: 0.2837\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.2911 - mse: 0.2911\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.2901 - mse: 0.2901\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.2881 - mse: 0.2881\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.2900 - mse: 0.2900\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2891 - mse: 0.2891\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2916 - mse: 0.2916\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.2883 - mse: 0.2883\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2928 - mse: 0.2928\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.2866 - mse: 0.2866\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 737us/step - loss: 0.2872 - mse: 0.2872\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.2883 - mse: 0.2883\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 721us/step - loss: 0.2896 - mse: 0.2896\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.2926 - mse: 0.2926\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 792us/step - loss: 0.2917 - mse: 0.2917\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2853 - mse: 0.2853\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2855 - mse: 0.2855\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 872us/step - loss: 0.2880 - mse: 0.2880\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 777us/step - loss: 0.2912 - mse: 0.2912\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 766us/step - loss: 0.2896 - mse: 0.2896\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 788us/step - loss: 0.2850 - mse: 0.2850\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.2883 - mse: 0.2883\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2892 - mse: 0.2892\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2877 - mse: 0.2877\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2874 - mse: 0.2874\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.2856 - mse: 0.2856\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2839 - mse: 0.2839\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 881us/step - loss: 0.2884 - mse: 0.2884\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2846 - mse: 0.2846\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 766us/step - loss: 0.2899 - mse: 0.2899\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.2845 - mse: 0.2845\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.2840 - mse: 0.2840\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 781us/step - loss: 0.2879 - mse: 0.2879\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2844 - mse: 0.2844\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.2869 - mse: 0.2869\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 788us/step - loss: 0.2854 - mse: 0.2854\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.2823 - mse: 0.2823\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.2892 - mse: 0.2892\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2839 - mse: 0.2839\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 703us/step - loss: 0.2879 - mse: 0.2879\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.2889 - mse: 0.2889\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 803us/step - loss: 0.2845 - mse: 0.2845\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 811us/step - loss: 0.2830 - mse: 0.2830\n",
      "23/23 [==============================] - 0s 580us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d7fb87226f7f4c0fb46ca4b543fdf8ca/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d7fb87226f7f4c0fb46ca4b543fdf8ca/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:14:52.976513: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://02c1fd6bf0534bcea66781a7229c46ae: INVALID_ARGUMENT: ram://02c1fd6bf0534bcea66781a7229c46ae is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 819us/step - loss: 0.6333 - mse: 0.6333\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.4712 - mse: 0.4712\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.4400 - mse: 0.4400\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 751us/step - loss: 0.4114 - mse: 0.4114\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 719us/step - loss: 0.3943 - mse: 0.3943\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3829 - mse: 0.3829\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 865us/step - loss: 0.3740 - mse: 0.3740\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.3679 - mse: 0.3679\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3659 - mse: 0.3659\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 783us/step - loss: 0.3626 - mse: 0.3626\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 800us/step - loss: 0.3549 - mse: 0.3549\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.3581 - mse: 0.3581\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 777us/step - loss: 0.3434 - mse: 0.3434\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.3350 - mse: 0.3350\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.3463 - mse: 0.3463\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.3379 - mse: 0.3379\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3356 - mse: 0.3356\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3380 - mse: 0.3380\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 771us/step - loss: 0.3407 - mse: 0.3407\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.3340 - mse: 0.3340\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.3266 - mse: 0.3266\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.3268 - mse: 0.3268\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.3206 - mse: 0.3206\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 789us/step - loss: 0.3246 - mse: 0.3246\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.3240 - mse: 0.3240\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.3249 - mse: 0.3249\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.3238 - mse: 0.3238\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.3234 - mse: 0.3234\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.3201 - mse: 0.3201\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 751us/step - loss: 0.3165 - mse: 0.3165\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.3127 - mse: 0.3127\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 776us/step - loss: 0.3159 - mse: 0.3159\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.3092 - mse: 0.3092\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.3128 - mse: 0.3128\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.3193 - mse: 0.3193\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.3113 - mse: 0.3113\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.3075 - mse: 0.3075\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.3055 - mse: 0.3055\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.3052 - mse: 0.3052\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3037 - mse: 0.3037\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 771us/step - loss: 0.3106 - mse: 0.3106\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.3086 - mse: 0.3086\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.3127 - mse: 0.3127\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.3114 - mse: 0.3114\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2990 - mse: 0.2990\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.3104 - mse: 0.3104\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3127 - mse: 0.3127\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3070 - mse: 0.3070\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.3055 - mse: 0.3055\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.3018 - mse: 0.3018\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.3048 - mse: 0.3048\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.3120 - mse: 0.3120\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.2979 - mse: 0.2979\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.3051 - mse: 0.3051\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.3018 - mse: 0.3018\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 804us/step - loss: 0.3011 - mse: 0.3011\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 779us/step - loss: 0.3055 - mse: 0.3055\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.3042 - mse: 0.3042\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2975 - mse: 0.2975\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.3037 - mse: 0.3037\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.3021 - mse: 0.3021\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.3056 - mse: 0.3056\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.2998 - mse: 0.2998\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3002 - mse: 0.3002\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.3039 - mse: 0.3039\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.3020 - mse: 0.3020\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 791us/step - loss: 0.2940 - mse: 0.2940\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.3005 - mse: 0.3005\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.2997 - mse: 0.2997\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.3010 - mse: 0.3010\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.3035 - mse: 0.3035\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.2951 - mse: 0.2951\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.3021 - mse: 0.3021\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 763us/step - loss: 0.3018 - mse: 0.3018\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 780us/step - loss: 0.2943 - mse: 0.2943\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 819us/step - loss: 0.3000 - mse: 0.3000\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 801us/step - loss: 0.2981 - mse: 0.2981\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2935 - mse: 0.2935\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 786us/step - loss: 0.3004 - mse: 0.3004\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 817us/step - loss: 0.2941 - mse: 0.2941\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 785us/step - loss: 0.2904 - mse: 0.2904\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2975 - mse: 0.2975\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 816us/step - loss: 0.2930 - mse: 0.2930\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 800us/step - loss: 0.2917 - mse: 0.2917\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 765us/step - loss: 0.2922 - mse: 0.2922\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 815us/step - loss: 0.2996 - mse: 0.2996\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.2944 - mse: 0.2944\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2924 - mse: 0.2924\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.3009 - mse: 0.3009\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 769us/step - loss: 0.2943 - mse: 0.2943\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2938 - mse: 0.2938\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2908 - mse: 0.2908\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.2911 - mse: 0.2911\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 722us/step - loss: 0.2927 - mse: 0.2927\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.3050 - mse: 0.3050\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2936 - mse: 0.2936\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.2903 - mse: 0.2903\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.2937 - mse: 0.2937\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.2943 - mse: 0.2943\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2958 - mse: 0.2958\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 815us/step - loss: 0.2862 - mse: 0.2862\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2911 - mse: 0.2911\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 813us/step - loss: 0.2908 - mse: 0.2908\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2965 - mse: 0.2965\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 798us/step - loss: 0.2943 - mse: 0.2943\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.2866 - mse: 0.2866\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2957 - mse: 0.2957\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 769us/step - loss: 0.2924 - mse: 0.2924\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2857 - mse: 0.2857\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.2928 - mse: 0.2928\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 795us/step - loss: 0.2887 - mse: 0.2887\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 781us/step - loss: 0.2897 - mse: 0.2897\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 783us/step - loss: 0.2907 - mse: 0.2907\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 940us/step - loss: 0.2871 - mse: 0.2871\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.2959 - mse: 0.2959\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2893 - mse: 0.2893\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 808us/step - loss: 0.2896 - mse: 0.2896\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 811us/step - loss: 0.2841 - mse: 0.2841\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 922us/step - loss: 0.3020 - mse: 0.3020\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2930 - mse: 0.2930\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 772us/step - loss: 0.2935 - mse: 0.2935\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 955us/step - loss: 0.2894 - mse: 0.2894\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.2847 - mse: 0.2847\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.2899 - mse: 0.2899\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2870 - mse: 0.2870\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.2917 - mse: 0.2917\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2876 - mse: 0.2876\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.2899 - mse: 0.2899\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.2877 - mse: 0.2877\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 797us/step - loss: 0.2887 - mse: 0.2887\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2862 - mse: 0.2862\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 911us/step - loss: 0.2823 - mse: 0.2823\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 806us/step - loss: 0.2899 - mse: 0.2899\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2891 - mse: 0.2891\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 703us/step - loss: 0.2860 - mse: 0.2860\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2869 - mse: 0.2869\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.2912 - mse: 0.2912\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 793us/step - loss: 0.2897 - mse: 0.2897\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 716us/step - loss: 0.2852 - mse: 0.2852\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 721us/step - loss: 0.2914 - mse: 0.2914\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.2913 - mse: 0.2913\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.2874 - mse: 0.2874\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.2836 - mse: 0.2836\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 718us/step - loss: 0.2874 - mse: 0.2874\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.2851 - mse: 0.2851\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 709us/step - loss: 0.2831 - mse: 0.2831\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 691us/step - loss: 0.2853 - mse: 0.2853\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 689us/step - loss: 0.2880 - mse: 0.2880\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.2918 - mse: 0.2918\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2911 - mse: 0.2911\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2914 - mse: 0.2914\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.2933 - mse: 0.2933\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.2830 - mse: 0.2830\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 726us/step - loss: 0.2887 - mse: 0.2887\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.2906 - mse: 0.2906\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 711us/step - loss: 0.2843 - mse: 0.2843\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 690us/step - loss: 0.2851 - mse: 0.2851\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.2844 - mse: 0.2844\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.2829 - mse: 0.2829\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 683us/step - loss: 0.2946 - mse: 0.2946\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 692us/step - loss: 0.2799 - mse: 0.2799\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.2854 - mse: 0.2854\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.2841 - mse: 0.2841\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.2863 - mse: 0.2863\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.2855 - mse: 0.2855\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2837 - mse: 0.2837\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 876us/step - loss: 0.2797 - mse: 0.2797\n",
      "Epoch 168/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2818 - mse: 0.2818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2817 - mse: 0.2817\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 981us/step - loss: 0.2863 - mse: 0.2863\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2870 - mse: 0.2870\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 885us/step - loss: 0.2833 - mse: 0.2833\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.2825 - mse: 0.2825\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 974us/step - loss: 0.2833 - mse: 0.2833\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.2819 - mse: 0.2819\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 909us/step - loss: 0.2874 - mse: 0.2874\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 984us/step - loss: 0.2906 - mse: 0.2906\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 819us/step - loss: 0.2844 - mse: 0.2844\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.2830 - mse: 0.2830\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2871 - mse: 0.2871\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 921us/step - loss: 0.2837 - mse: 0.2837\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 813us/step - loss: 0.2835 - mse: 0.2835\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2843 - mse: 0.2843\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 993us/step - loss: 0.2810 - mse: 0.2810\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 884us/step - loss: 0.2884 - mse: 0.2884\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 861us/step - loss: 0.2789 - mse: 0.2789\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 988us/step - loss: 0.2875 - mse: 0.2875\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 881us/step - loss: 0.2835 - mse: 0.2835\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 857us/step - loss: 0.2869 - mse: 0.2869\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 859us/step - loss: 0.2832 - mse: 0.2832\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2848 - mse: 0.2848\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2854 - mse: 0.2854\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2811 - mse: 0.2811\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 801us/step - loss: 0.2815 - mse: 0.2815\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.2840 - mse: 0.2840\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.2845 - mse: 0.2845\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.2837 - mse: 0.2837\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.2841 - mse: 0.2841\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 915us/step - loss: 0.2881 - mse: 0.2881\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.2806 - mse: 0.2806\n",
      "23/23 [==============================] - 0s 652us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://af6e1681625f4b1f9d390c1da39065be/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://af6e1681625f4b1f9d390c1da39065be/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:15:08.586360: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://a5e98b292b17479db33196ae99a02b38: INVALID_ARGUMENT: ram://a5e98b292b17479db33196ae99a02b38 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 815us/step - loss: 0.6150 - mse: 0.6150\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.4763 - mse: 0.4763\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 802us/step - loss: 0.4409 - mse: 0.4409\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 894us/step - loss: 0.4132 - mse: 0.4132\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 922us/step - loss: 0.3906 - mse: 0.3906\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 797us/step - loss: 0.3840 - mse: 0.3840\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 784us/step - loss: 0.3732 - mse: 0.3732\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.3701 - mse: 0.3701\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.3651 - mse: 0.3651\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.3622 - mse: 0.3622\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 710us/step - loss: 0.3611 - mse: 0.3611\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.3514 - mse: 0.3514\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 711us/step - loss: 0.3400 - mse: 0.3400\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.3475 - mse: 0.3475\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.3492 - mse: 0.3492\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 794us/step - loss: 0.3384 - mse: 0.3384\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.3462 - mse: 0.3462\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.3310 - mse: 0.3310\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.3339 - mse: 0.3339\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 711us/step - loss: 0.3367 - mse: 0.3367\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.3341 - mse: 0.3341\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.3336 - mse: 0.3336\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.3356 - mse: 0.3356\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.3234 - mse: 0.3234\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.3235 - mse: 0.3235\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 766us/step - loss: 0.3277 - mse: 0.3277\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.3232 - mse: 0.3232\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.3199 - mse: 0.3199\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.3257 - mse: 0.3257\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.3150 - mse: 0.3150\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.3186 - mse: 0.3186\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 714us/step - loss: 0.3120 - mse: 0.3120\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 818us/step - loss: 0.3151 - mse: 0.3151\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 800us/step - loss: 0.3194 - mse: 0.3194\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.3124 - mse: 0.3124\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 793us/step - loss: 0.3147 - mse: 0.3147\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.3081 - mse: 0.3081\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.3066 - mse: 0.3066\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.3146 - mse: 0.3146\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.3073 - mse: 0.3073\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 783us/step - loss: 0.3090 - mse: 0.3090\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.3104 - mse: 0.3104\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 712us/step - loss: 0.3092 - mse: 0.3092\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.3055 - mse: 0.3055\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 714us/step - loss: 0.3025 - mse: 0.3025\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.3069 - mse: 0.3069\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 727us/step - loss: 0.3093 - mse: 0.3093\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 871us/step - loss: 0.3080 - mse: 0.3080\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 801us/step - loss: 0.3106 - mse: 0.3106\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.3026 - mse: 0.3026\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.3059 - mse: 0.3059\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.3121 - mse: 0.3121\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.3090 - mse: 0.3090\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2948 - mse: 0.2948\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2976 - mse: 0.2976\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3108 - mse: 0.3108\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3036 - mse: 0.3036\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 751us/step - loss: 0.3046 - mse: 0.3046\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 872us/step - loss: 0.3015 - mse: 0.3015\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.3000 - mse: 0.3000\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 803us/step - loss: 0.2977 - mse: 0.2977\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 802us/step - loss: 0.2996 - mse: 0.2996\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 790us/step - loss: 0.3047 - mse: 0.3047\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 929us/step - loss: 0.3035 - mse: 0.3035\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 884us/step - loss: 0.2974 - mse: 0.2974\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 885us/step - loss: 0.3020 - mse: 0.3020\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 799us/step - loss: 0.2959 - mse: 0.2959\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 779us/step - loss: 0.2982 - mse: 0.2982\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 775us/step - loss: 0.2941 - mse: 0.2941\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 920us/step - loss: 0.2954 - mse: 0.2954\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2995 - mse: 0.2995\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 930us/step - loss: 0.2987 - mse: 0.2987\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.3026 - mse: 0.3026\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 824us/step - loss: 0.2972 - mse: 0.2972\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.2978 - mse: 0.2978\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.2953 - mse: 0.2953\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 766us/step - loss: 0.2972 - mse: 0.2972\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.2958 - mse: 0.2958\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.2970 - mse: 0.2970\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 763us/step - loss: 0.2971 - mse: 0.2971\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3013 - mse: 0.3013\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2929 - mse: 0.2929\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 787us/step - loss: 0.3047 - mse: 0.3047\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.2946 - mse: 0.2946\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 729us/step - loss: 0.2939 - mse: 0.2939\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.2886 - mse: 0.2886\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.2970 - mse: 0.2970\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2866 - mse: 0.2866\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.2883 - mse: 0.2883\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.2913 - mse: 0.2913\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2923 - mse: 0.2923\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.3000 - mse: 0.3000\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3019 - mse: 0.3019\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2967 - mse: 0.2967\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 746us/step - loss: 0.2958 - mse: 0.2958\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2941 - mse: 0.2941\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 772us/step - loss: 0.2940 - mse: 0.2940\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.2939 - mse: 0.2939\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2941 - mse: 0.2941\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 885us/step - loss: 0.2885 - mse: 0.2885\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 772us/step - loss: 0.2975 - mse: 0.2975\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2938 - mse: 0.2938\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2937 - mse: 0.2937\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2869 - mse: 0.2869\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2902 - mse: 0.2902\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.2896 - mse: 0.2896\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2915 - mse: 0.2915\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2997 - mse: 0.2997\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2902 - mse: 0.2902\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2897 - mse: 0.2897\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2873 - mse: 0.2873\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.2872 - mse: 0.2872\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2891 - mse: 0.2891\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2931 - mse: 0.2931\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.3002 - mse: 0.3002\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2934 - mse: 0.2934\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 726us/step - loss: 0.2906 - mse: 0.2906\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2940 - mse: 0.2940\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 751us/step - loss: 0.2919 - mse: 0.2919\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2873 - mse: 0.2873\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.2923 - mse: 0.2923\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2931 - mse: 0.2931\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2940 - mse: 0.2940\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2918 - mse: 0.2918\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.2867 - mse: 0.2867\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2900 - mse: 0.2900\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2858 - mse: 0.2858\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2868 - mse: 0.2868\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.2886 - mse: 0.2886\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.2892 - mse: 0.2892\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 802us/step - loss: 0.2931 - mse: 0.2931\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2932 - mse: 0.2932\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.2839 - mse: 0.2839\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2869 - mse: 0.2869\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2889 - mse: 0.2889\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.2875 - mse: 0.2875\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2797 - mse: 0.2797\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2897 - mse: 0.2897\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2906 - mse: 0.2906\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2865 - mse: 0.2865\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2837 - mse: 0.2837\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.2875 - mse: 0.2875\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2867 - mse: 0.2867\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2886 - mse: 0.2886\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2871 - mse: 0.2871\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2861 - mse: 0.2861\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2897 - mse: 0.2897\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 763us/step - loss: 0.2862 - mse: 0.2862\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 895us/step - loss: 0.2908 - mse: 0.2908\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.2842 - mse: 0.2842\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2899 - mse: 0.2899\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 770us/step - loss: 0.2867 - mse: 0.2867\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2831 - mse: 0.2831\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2850 - mse: 0.2850\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2840 - mse: 0.2840\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2877 - mse: 0.2877\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 769us/step - loss: 0.2872 - mse: 0.2872\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2852 - mse: 0.2852\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 747us/step - loss: 0.2907 - mse: 0.2907\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 772us/step - loss: 0.2897 - mse: 0.2897\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 753us/step - loss: 0.2873 - mse: 0.2873\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 796us/step - loss: 0.2835 - mse: 0.2835\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 788us/step - loss: 0.2907 - mse: 0.2907\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2873 - mse: 0.2873\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 780us/step - loss: 0.2728 - mse: 0.2728\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 770us/step - loss: 0.2904 - mse: 0.2904\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.2869 - mse: 0.2869\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 900us/step - loss: 0.2852 - mse: 0.2852\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2866 - mse: 0.2866\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2820 - mse: 0.2820\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2787 - mse: 0.2787\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.2809 - mse: 0.2809\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.2883 - mse: 0.2883\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 759us/step - loss: 0.2865 - mse: 0.2865\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2820 - mse: 0.2820\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 992us/step - loss: 0.2801 - mse: 0.2801\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 787us/step - loss: 0.2857 - mse: 0.2857\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 772us/step - loss: 0.2872 - mse: 0.2872\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 769us/step - loss: 0.2852 - mse: 0.2852\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.2815 - mse: 0.2815\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 750us/step - loss: 0.2890 - mse: 0.2890\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2812 - mse: 0.2812\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 732us/step - loss: 0.2822 - mse: 0.2822\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2840 - mse: 0.2840\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.2806 - mse: 0.2806\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.2774 - mse: 0.2774\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2856 - mse: 0.2856\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2801 - mse: 0.2801\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 796us/step - loss: 0.2847 - mse: 0.2847\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 764us/step - loss: 0.2853 - mse: 0.2853\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2793 - mse: 0.2793\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.2852 - mse: 0.2852\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.2808 - mse: 0.2808\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2817 - mse: 0.2817\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 754us/step - loss: 0.2858 - mse: 0.2858\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2798 - mse: 0.2798\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2830 - mse: 0.2830\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 997us/step - loss: 0.2830 - mse: 0.2830\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 758us/step - loss: 0.2774 - mse: 0.2774\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.2923 - mse: 0.2923\n",
      "23/23 [==============================] - 0s 565us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6878e93100824829b2f62c535f27b58e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6878e93100824829b2f62c535f27b58e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:15:23.752376: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://7bf2dc42b7b24a4eba2eb181260c1bf1: INVALID_ARGUMENT: ram://7bf2dc42b7b24a4eba2eb181260c1bf1 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 782us/step - loss: 0.6203 - mse: 0.6203\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.4854 - mse: 0.4854\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 722us/step - loss: 0.4206 - mse: 0.4206\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 770us/step - loss: 0.4084 - mse: 0.4084\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.3863 - mse: 0.3863\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.3836 - mse: 0.3836\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.3840 - mse: 0.3840\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 725us/step - loss: 0.3577 - mse: 0.3577\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.3698 - mse: 0.3698\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.3647 - mse: 0.3647\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.3587 - mse: 0.3587\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.3579 - mse: 0.3579\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.3489 - mse: 0.3489\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.3515 - mse: 0.3515\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 723us/step - loss: 0.3387 - mse: 0.3387\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.3363 - mse: 0.3363\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 722us/step - loss: 0.3379 - mse: 0.3379\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.3388 - mse: 0.3388\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.3360 - mse: 0.3360\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3377 - mse: 0.3377\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.3262 - mse: 0.3262\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3334 - mse: 0.3334\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 734us/step - loss: 0.3249 - mse: 0.3249\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3247 - mse: 0.3247\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.3268 - mse: 0.3268\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.3208 - mse: 0.3208\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 737us/step - loss: 0.3146 - mse: 0.3146\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.3213 - mse: 0.3213\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.3219 - mse: 0.3219\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 730us/step - loss: 0.3195 - mse: 0.3195\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 783us/step - loss: 0.3166 - mse: 0.3166\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 782us/step - loss: 0.3157 - mse: 0.3157\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.3174 - mse: 0.3174\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.3168 - mse: 0.3168\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 757us/step - loss: 0.3092 - mse: 0.3092\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 742us/step - loss: 0.3076 - mse: 0.3076\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 721us/step - loss: 0.3078 - mse: 0.3078\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.3066 - mse: 0.3066\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.3067 - mse: 0.3067\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.3122 - mse: 0.3122\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.3069 - mse: 0.3069\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.3062 - mse: 0.3062\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 779us/step - loss: 0.3094 - mse: 0.3094\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 745us/step - loss: 0.3092 - mse: 0.3092\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 792us/step - loss: 0.3051 - mse: 0.3051\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.3051 - mse: 0.3051\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2987 - mse: 0.2987\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.3086 - mse: 0.3086\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.3074 - mse: 0.3074\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.3039 - mse: 0.3039\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2961 - mse: 0.2961\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.2988 - mse: 0.2988\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.3015 - mse: 0.3015\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 779us/step - loss: 0.2948 - mse: 0.2948\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 783us/step - loss: 0.3039 - mse: 0.3039\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.3005 - mse: 0.3005\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.3006 - mse: 0.3006\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 821us/step - loss: 0.2903 - mse: 0.2903\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2994 - mse: 0.2994\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 804us/step - loss: 0.2977 - mse: 0.2977\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2995 - mse: 0.2995\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 783us/step - loss: 0.2953 - mse: 0.2953\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 818us/step - loss: 0.2981 - mse: 0.2981\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2991 - mse: 0.2991\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 743us/step - loss: 0.2962 - mse: 0.2962\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 810us/step - loss: 0.2955 - mse: 0.2955\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 771us/step - loss: 0.2950 - mse: 0.2950\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 787us/step - loss: 0.2982 - mse: 0.2982\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 795us/step - loss: 0.2904 - mse: 0.2904\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 807us/step - loss: 0.2975 - mse: 0.2975\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 785us/step - loss: 0.2921 - mse: 0.2921\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 784us/step - loss: 0.2977 - mse: 0.2977\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 766us/step - loss: 0.2951 - mse: 0.2951\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 792us/step - loss: 0.2991 - mse: 0.2991\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 767us/step - loss: 0.2882 - mse: 0.2882\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 788us/step - loss: 0.2927 - mse: 0.2927\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 775us/step - loss: 0.2915 - mse: 0.2915\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.2933 - mse: 0.2933\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.2860 - mse: 0.2860\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 815us/step - loss: 0.2976 - mse: 0.2976\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 775us/step - loss: 0.2875 - mse: 0.2875\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 778us/step - loss: 0.2923 - mse: 0.2923\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 787us/step - loss: 0.2970 - mse: 0.2970\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 967us/step - loss: 0.2943 - mse: 0.2943\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 854us/step - loss: 0.2909 - mse: 0.2909\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 880us/step - loss: 0.2962 - mse: 0.2962\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.2994 - mse: 0.2994\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 802us/step - loss: 0.2896 - mse: 0.2896\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 819us/step - loss: 0.2926 - mse: 0.2926\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 808us/step - loss: 0.2976 - mse: 0.2976\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.2899 - mse: 0.2899\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 907us/step - loss: 0.2940 - mse: 0.2940\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 884us/step - loss: 0.2880 - mse: 0.2880\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 889us/step - loss: 0.2909 - mse: 0.2909\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 859us/step - loss: 0.2912 - mse: 0.2912\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 787us/step - loss: 0.2951 - mse: 0.2951\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 799us/step - loss: 0.2888 - mse: 0.2888\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 985us/step - loss: 0.2951 - mse: 0.2951\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2938 - mse: 0.2938\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2875 - mse: 0.2875\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 881us/step - loss: 0.2936 - mse: 0.2936\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.2914 - mse: 0.2914\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2922 - mse: 0.2922\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 790us/step - loss: 0.2933 - mse: 0.2933\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 713us/step - loss: 0.2902 - mse: 0.2902\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 786us/step - loss: 0.2921 - mse: 0.2921\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 705us/step - loss: 0.2899 - mse: 0.2899\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 780us/step - loss: 0.2844 - mse: 0.2844\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 731us/step - loss: 0.2896 - mse: 0.2896\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 771us/step - loss: 0.2884 - mse: 0.2884\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 797us/step - loss: 0.2907 - mse: 0.2907\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 791us/step - loss: 0.2918 - mse: 0.2918\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.2904 - mse: 0.2904\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 782us/step - loss: 0.2876 - mse: 0.2876\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.2868 - mse: 0.2868\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 751us/step - loss: 0.2929 - mse: 0.2929\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2929 - mse: 0.2929\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 721us/step - loss: 0.2973 - mse: 0.2973\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 719us/step - loss: 0.2904 - mse: 0.2904\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2953 - mse: 0.2953\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2881 - mse: 0.2881\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.2886 - mse: 0.2886\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 688us/step - loss: 0.2945 - mse: 0.2945\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.2853 - mse: 0.2853\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 764us/step - loss: 0.2899 - mse: 0.2899\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 704us/step - loss: 0.2885 - mse: 0.2885\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 693us/step - loss: 0.2876 - mse: 0.2876\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 770us/step - loss: 0.2862 - mse: 0.2862\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 735us/step - loss: 0.2931 - mse: 0.2931\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 783us/step - loss: 0.2849 - mse: 0.2849\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 738us/step - loss: 0.2936 - mse: 0.2936\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 772us/step - loss: 0.2878 - mse: 0.2878\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 716us/step - loss: 0.2870 - mse: 0.2870\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 772us/step - loss: 0.2860 - mse: 0.2860\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 751us/step - loss: 0.2884 - mse: 0.2884\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 773us/step - loss: 0.2859 - mse: 0.2859\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 771us/step - loss: 0.2779 - mse: 0.2779\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 776us/step - loss: 0.2876 - mse: 0.2876\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.2896 - mse: 0.2896\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 789us/step - loss: 0.2854 - mse: 0.2854\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 767us/step - loss: 0.2899 - mse: 0.2899\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 749us/step - loss: 0.2902 - mse: 0.2902\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.2894 - mse: 0.2894\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 724us/step - loss: 0.2917 - mse: 0.2917\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 710us/step - loss: 0.2855 - mse: 0.2855\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 752us/step - loss: 0.2896 - mse: 0.2896\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2876 - mse: 0.2876\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.2839 - mse: 0.2839\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.2840 - mse: 0.2840\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 760us/step - loss: 0.2875 - mse: 0.2875\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.2868 - mse: 0.2868\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 733us/step - loss: 0.2848 - mse: 0.2848\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.2827 - mse: 0.2827\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 805us/step - loss: 0.2836 - mse: 0.2836\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 717us/step - loss: 0.2830 - mse: 0.2830\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 756us/step - loss: 0.2868 - mse: 0.2868\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 759us/step - loss: 0.2853 - mse: 0.2853\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 711us/step - loss: 0.2865 - mse: 0.2865\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2859 - mse: 0.2859\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.2863 - mse: 0.2863\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.2824 - mse: 0.2824\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 950us/step - loss: 0.2904 - mse: 0.2904\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2860 - mse: 0.2860\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 768us/step - loss: 0.2789 - mse: 0.2789\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 780us/step - loss: 0.2817 - mse: 0.2817\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.2807 - mse: 0.2807\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 791us/step - loss: 0.2863 - mse: 0.2863\n",
      "Epoch 168/200\n",
      "91/91 [==============================] - 0s 765us/step - loss: 0.2825 - mse: 0.2825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 703us/step - loss: 0.2857 - mse: 0.2857\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.2838 - mse: 0.2838\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 781us/step - loss: 0.2832 - mse: 0.2832\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.2809 - mse: 0.2809\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2920 - mse: 0.2920\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 816us/step - loss: 0.2860 - mse: 0.2860\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.2827 - mse: 0.2827\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 896us/step - loss: 0.2808 - mse: 0.2808\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 748us/step - loss: 0.2867 - mse: 0.2867\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 696us/step - loss: 0.2875 - mse: 0.2875\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 787us/step - loss: 0.2849 - mse: 0.2849\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 703us/step - loss: 0.2797 - mse: 0.2797\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 684us/step - loss: 0.2844 - mse: 0.2844\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.2862 - mse: 0.2862\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 681us/step - loss: 0.2850 - mse: 0.2850\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2796 - mse: 0.2796\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 797us/step - loss: 0.2760 - mse: 0.2760\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 949us/step - loss: 0.2831 - mse: 0.2831\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.2774 - mse: 0.2774\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 937us/step - loss: 0.2838 - mse: 0.2838\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2808 - mse: 0.2808\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 905us/step - loss: 0.2789 - mse: 0.2789\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 729us/step - loss: 0.2838 - mse: 0.2838\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 996us/step - loss: 0.2840 - mse: 0.2840\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 782us/step - loss: 0.2820 - mse: 0.2820\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 878us/step - loss: 0.2798 - mse: 0.2798\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 764us/step - loss: 0.2801 - mse: 0.2801\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 784us/step - loss: 0.2859 - mse: 0.2859\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 882us/step - loss: 0.2807 - mse: 0.2807\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2902 - mse: 0.2902\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 929us/step - loss: 0.2834 - mse: 0.2834\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.2811 - mse: 0.2811\n",
      "23/23 [==============================] - 0s 645us/step\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several mintes to run\n",
    "# Generate cross-validated predictions\n",
    "np.random.seed(123)\n",
    "cv_dropout_preds = cross_val_predict(keras_wrapper_3, X_train_all, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46923648262155143"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE on train data (scaled)\n",
    "np.sqrt(mean_squared_error(y_train_scaled, cv_dropout_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that returns a compiled Keras model \n",
    "import keras\n",
    "\n",
    "def create_regularized_model2():\n",
    "    \n",
    "    # Initialize model\n",
    "    model = models.Sequential()\n",
    "    model.add(keras.Input(shape=n_features,))\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(layers.Dense(50,\n",
    "                           activation='relu',\n",
    "                           kernel_regularizer=keras.regularizers.L2(0.005)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Second hidden layer\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='SGD', \n",
    "                  loss='mse',  \n",
    "                  metrics=['mse']) \n",
    "    \n",
    "    # Return the compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6269a8e5ceb144188a15050954b779cd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6269a8e5ceb144188a15050954b779cd/assets\n",
      "2023-03-13 14:21:29.054516: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://8d78022cb5d8411b91f790448902f940: INVALID_ARGUMENT: ram://8d78022cb5d8411b91f790448902f940 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "91/91 [==============================] - 0s 934us/step - loss: 0.7293 - mse: 0.5863\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 889us/step - loss: 0.5692 - mse: 0.4295\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 939us/step - loss: 0.5285 - mse: 0.3918\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 956us/step - loss: 0.5035 - mse: 0.3697\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 882us/step - loss: 0.4937 - mse: 0.3628\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 912us/step - loss: 0.4789 - mse: 0.3507\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 920us/step - loss: 0.4722 - mse: 0.3466\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 914us/step - loss: 0.4610 - mse: 0.3380\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 872us/step - loss: 0.4560 - mse: 0.3355\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.4502 - mse: 0.3321\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.4399 - mse: 0.3241\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.4330 - mse: 0.3195\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 907us/step - loss: 0.4331 - mse: 0.3218\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 970us/step - loss: 0.4233 - mse: 0.3141\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 947us/step - loss: 0.4113 - mse: 0.3044\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 955us/step - loss: 0.4156 - mse: 0.3107\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 902us/step - loss: 0.4077 - mse: 0.3049\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 869us/step - loss: 0.4098 - mse: 0.3090\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 871us/step - loss: 0.4014 - mse: 0.3025\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 857us/step - loss: 0.4049 - mse: 0.3079\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.3945 - mse: 0.2993\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 857us/step - loss: 0.3909 - mse: 0.2976\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 883us/step - loss: 0.3963 - mse: 0.3048\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 859us/step - loss: 0.3913 - mse: 0.3014\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 859us/step - loss: 0.3891 - mse: 0.3009\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 863us/step - loss: 0.3800 - mse: 0.2935\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.3812 - mse: 0.2964\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 875us/step - loss: 0.3831 - mse: 0.2999\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 874us/step - loss: 0.3678 - mse: 0.2862\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 936us/step - loss: 0.3728 - mse: 0.2927\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 902us/step - loss: 0.3667 - mse: 0.2881\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 893us/step - loss: 0.3549 - mse: 0.2778\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 916us/step - loss: 0.3722 - mse: 0.2966\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 956us/step - loss: 0.3630 - mse: 0.2888\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 906us/step - loss: 0.3657 - mse: 0.2929\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 900us/step - loss: 0.3654 - mse: 0.2939\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 897us/step - loss: 0.3586 - mse: 0.2885\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 902us/step - loss: 0.3486 - mse: 0.2797\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 895us/step - loss: 0.3498 - mse: 0.2822\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 923us/step - loss: 0.3475 - mse: 0.2812\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 905us/step - loss: 0.3468 - mse: 0.2817\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 902us/step - loss: 0.3534 - mse: 0.2896\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 893us/step - loss: 0.3531 - mse: 0.2905\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 921us/step - loss: 0.3368 - mse: 0.2753\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 918us/step - loss: 0.3458 - mse: 0.2854\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 915us/step - loss: 0.3455 - mse: 0.2862\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 983us/step - loss: 0.3416 - mse: 0.2834\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 937us/step - loss: 0.3391 - mse: 0.2820\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 865us/step - loss: 0.3344 - mse: 0.2783\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 936us/step - loss: 0.3341 - mse: 0.2791\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 891us/step - loss: 0.3286 - mse: 0.2745\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 910us/step - loss: 0.3273 - mse: 0.2742\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 889us/step - loss: 0.3288 - mse: 0.2767\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 892us/step - loss: 0.3307 - mse: 0.2795\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 888us/step - loss: 0.3335 - mse: 0.2833\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 873us/step - loss: 0.3310 - mse: 0.2817\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.3235 - mse: 0.2751\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3288 - mse: 0.2813\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.3203 - mse: 0.2737\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.3185 - mse: 0.2727\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.3160 - mse: 0.2710\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 877us/step - loss: 0.3163 - mse: 0.2721\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.3181 - mse: 0.2747\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 972us/step - loss: 0.3194 - mse: 0.2768\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 910us/step - loss: 0.3081 - mse: 0.2662\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 911us/step - loss: 0.3188 - mse: 0.2777\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 900us/step - loss: 0.3123 - mse: 0.2719\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.3085 - mse: 0.2689\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.3178 - mse: 0.2789\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 906us/step - loss: 0.3133 - mse: 0.2750\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 883us/step - loss: 0.3146 - mse: 0.2770\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.3090 - mse: 0.2721\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 891us/step - loss: 0.3159 - mse: 0.2797\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 869us/step - loss: 0.3033 - mse: 0.2677\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 900us/step - loss: 0.3083 - mse: 0.2733\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 876us/step - loss: 0.3120 - mse: 0.2776\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 902us/step - loss: 0.3111 - mse: 0.2774\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.3097 - mse: 0.2765\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 869us/step - loss: 0.3059 - mse: 0.2733\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 897us/step - loss: 0.3030 - mse: 0.2710\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 918us/step - loss: 0.3024 - mse: 0.2709\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 874us/step - loss: 0.3058 - mse: 0.2748\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 881us/step - loss: 0.3012 - mse: 0.2708\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 918us/step - loss: 0.3029 - mse: 0.2730\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 859us/step - loss: 0.3000 - mse: 0.2706\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 856us/step - loss: 0.2961 - mse: 0.2673\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 891us/step - loss: 0.3054 - mse: 0.2770\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 855us/step - loss: 0.2957 - mse: 0.2679\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 915us/step - loss: 0.2982 - mse: 0.2708\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 886us/step - loss: 0.2990 - mse: 0.2720\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 907us/step - loss: 0.2951 - mse: 0.2686\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.2914 - mse: 0.2653\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.2955 - mse: 0.2699\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 957us/step - loss: 0.2971 - mse: 0.2719\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 957us/step - loss: 0.2915 - mse: 0.2667\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2928 - mse: 0.2685\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 960us/step - loss: 0.2902 - mse: 0.2663\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 952us/step - loss: 0.2907 - mse: 0.2671\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 869us/step - loss: 0.2913 - mse: 0.2682\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 898us/step - loss: 0.2878 - mse: 0.2650\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 951us/step - loss: 0.2854 - mse: 0.2630\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 874us/step - loss: 0.2894 - mse: 0.2674\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 875us/step - loss: 0.2956 - mse: 0.2739\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 892us/step - loss: 0.2850 - mse: 0.2637\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2878 - mse: 0.2668\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.2903 - mse: 0.2697\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.2904 - mse: 0.2701\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 857us/step - loss: 0.2890 - mse: 0.2691\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 857us/step - loss: 0.2906 - mse: 0.2710\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2905 - mse: 0.2711\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.2834 - mse: 0.2643\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.2877 - mse: 0.2689\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.2917 - mse: 0.2732\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 873us/step - loss: 0.2835 - mse: 0.2654\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 900us/step - loss: 0.2828 - mse: 0.2650\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 888us/step - loss: 0.2854 - mse: 0.2678\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.2845 - mse: 0.2672\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2809 - mse: 0.2639\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.2824 - mse: 0.2656\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.2849 - mse: 0.2683\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 868us/step - loss: 0.2810 - mse: 0.2648\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.2849 - mse: 0.2689\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.2825 - mse: 0.2667\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 868us/step - loss: 0.2827 - mse: 0.2672\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 856us/step - loss: 0.2857 - mse: 0.2704\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.2762 - mse: 0.2611\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 958us/step - loss: 0.2776 - mse: 0.2628\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2854 - mse: 0.2708\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 869us/step - loss: 0.2759 - mse: 0.2615\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 821us/step - loss: 0.2762 - mse: 0.2620\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2769 - mse: 0.2629\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.2790 - mse: 0.2652\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 868us/step - loss: 0.2801 - mse: 0.2666\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.2800 - mse: 0.2667\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2817 - mse: 0.2685\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2779 - mse: 0.2649\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.2790 - mse: 0.2662\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 816us/step - loss: 0.2740 - mse: 0.2614\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 818us/step - loss: 0.2785 - mse: 0.2661\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2751 - mse: 0.2628\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 864us/step - loss: 0.2760 - mse: 0.2639\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.2786 - mse: 0.2667\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.2696 - mse: 0.2579\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 895us/step - loss: 0.2755 - mse: 0.2639\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 920us/step - loss: 0.2737 - mse: 0.2623\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 892us/step - loss: 0.2725 - mse: 0.2612\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.2723 - mse: 0.2612\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 971us/step - loss: 0.2746 - mse: 0.2636\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 918us/step - loss: 0.2782 - mse: 0.2674\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 867us/step - loss: 0.2743 - mse: 0.2636\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 894us/step - loss: 0.2787 - mse: 0.2681\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 914us/step - loss: 0.2768 - mse: 0.2664\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 895us/step - loss: 0.2749 - mse: 0.2647\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 897us/step - loss: 0.2732 - mse: 0.2631\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 967us/step - loss: 0.2713 - mse: 0.2613\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 916us/step - loss: 0.2738 - mse: 0.2640\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 912us/step - loss: 0.2743 - mse: 0.2646\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 869us/step - loss: 0.2758 - mse: 0.2662\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 871us/step - loss: 0.2688 - mse: 0.2593\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 900us/step - loss: 0.2751 - mse: 0.2658\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 883us/step - loss: 0.2607 - mse: 0.2515\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 891us/step - loss: 0.2699 - mse: 0.2608\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 919us/step - loss: 0.2696 - mse: 0.2606\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 879us/step - loss: 0.2678 - mse: 0.2589\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.2720 - mse: 0.2633\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 901us/step - loss: 0.2742 - mse: 0.2655\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 868us/step - loss: 0.2759 - mse: 0.2673\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 843us/step - loss: 0.2742 - mse: 0.2657\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 978us/step - loss: 0.2726 - mse: 0.2642\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 909us/step - loss: 0.2737 - mse: 0.2655\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 888us/step - loss: 0.2640 - mse: 0.2559\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 879us/step - loss: 0.2668 - mse: 0.2587\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2709 - mse: 0.2629\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 871us/step - loss: 0.2662 - mse: 0.2584\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2647 - mse: 0.2569\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 869us/step - loss: 0.2766 - mse: 0.2688\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 877us/step - loss: 0.2795 - mse: 0.2719\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.2696 - mse: 0.2620\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2714 - mse: 0.2640\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.2724 - mse: 0.2650\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 812us/step - loss: 0.2712 - mse: 0.2639\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2744 - mse: 0.2672\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 821us/step - loss: 0.2669 - mse: 0.2598\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 811us/step - loss: 0.2650 - mse: 0.2579\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2706 - mse: 0.2636\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.2748 - mse: 0.2680\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2688 - mse: 0.2619\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2704 - mse: 0.2636\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.2741 - mse: 0.2675\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.2662 - mse: 0.2596\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2683 - mse: 0.2617\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2699 - mse: 0.2634\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.2634 - mse: 0.2570\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.2597 - mse: 0.2534\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2695 - mse: 0.2632\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2667 - mse: 0.2605\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.2692 - mse: 0.2631\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2645 - mse: 0.2583\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.2717 - mse: 0.2657\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2651 - mse: 0.2591\n",
      "23/23 [==============================] - 0s 589us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://953de762660d433eb8e79fbbc0bedbe6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://953de762660d433eb8e79fbbc0bedbe6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:21:46.183607: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://0d16a9bff0d04e9b85da3161b282b858: INVALID_ARGUMENT: ram://0d16a9bff0d04e9b85da3161b282b858 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 969us/step - loss: 0.7314 - mse: 0.5885\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 896us/step - loss: 0.5567 - mse: 0.4169\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 930us/step - loss: 0.5385 - mse: 0.4018\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 889us/step - loss: 0.5185 - mse: 0.3847\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 923us/step - loss: 0.4996 - mse: 0.3685\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 872us/step - loss: 0.4901 - mse: 0.3617\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 859us/step - loss: 0.4780 - mse: 0.3522\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 856us/step - loss: 0.4723 - mse: 0.3491\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 893us/step - loss: 0.4564 - mse: 0.3357\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 913us/step - loss: 0.4533 - mse: 0.3351\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 879us/step - loss: 0.4455 - mse: 0.3295\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 900us/step - loss: 0.4408 - mse: 0.3271\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 880us/step - loss: 0.4375 - mse: 0.3261\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 891us/step - loss: 0.4313 - mse: 0.3221\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 863us/step - loss: 0.4257 - mse: 0.3187\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 924us/step - loss: 0.4236 - mse: 0.3186\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 922us/step - loss: 0.4136 - mse: 0.3106\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 989us/step - loss: 0.4128 - mse: 0.3117\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 898us/step - loss: 0.4069 - mse: 0.3078\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 881us/step - loss: 0.4059 - mse: 0.3087\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.4053 - mse: 0.3100\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.4064 - mse: 0.3130\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.4030 - mse: 0.3113\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.3949 - mse: 0.3050\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3889 - mse: 0.3006\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.3907 - mse: 0.3041\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.3871 - mse: 0.3022\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 886us/step - loss: 0.3792 - mse: 0.2958\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 928us/step - loss: 0.3819 - mse: 0.3001\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 880us/step - loss: 0.3744 - mse: 0.2942\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 885us/step - loss: 0.3733 - mse: 0.2946\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.3758 - mse: 0.2986\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.3735 - mse: 0.2977\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 856us/step - loss: 0.3721 - mse: 0.2978\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.3638 - mse: 0.2909\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 872us/step - loss: 0.3659 - mse: 0.2943\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.3601 - mse: 0.2899\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.3617 - mse: 0.2928\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 856us/step - loss: 0.3558 - mse: 0.2881\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 874us/step - loss: 0.3591 - mse: 0.2927\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3526 - mse: 0.2875\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.3513 - mse: 0.2874\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.3486 - mse: 0.2859\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.3478 - mse: 0.2862\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.3413 - mse: 0.2809\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 857us/step - loss: 0.3490 - mse: 0.2897\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 872us/step - loss: 0.3452 - mse: 0.2870\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 866us/step - loss: 0.3401 - mse: 0.2830\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.3436 - mse: 0.2875\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.3490 - mse: 0.2940\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.3399 - mse: 0.2858\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3409 - mse: 0.2879\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 963us/step - loss: 0.3362 - mse: 0.2842\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3394 - mse: 0.2883\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 883us/step - loss: 0.3302 - mse: 0.2800\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 899us/step - loss: 0.3339 - mse: 0.2846\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 883us/step - loss: 0.3285 - mse: 0.2801\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 879us/step - loss: 0.3276 - mse: 0.2801\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 936us/step - loss: 0.3236 - mse: 0.2770\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 909us/step - loss: 0.3234 - mse: 0.2776\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 948us/step - loss: 0.3230 - mse: 0.2781\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3291 - mse: 0.2850\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 867us/step - loss: 0.3283 - mse: 0.2850\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 907us/step - loss: 0.3201 - mse: 0.2775\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 883us/step - loss: 0.3205 - mse: 0.2788\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 899us/step - loss: 0.3227 - mse: 0.2816\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3208 - mse: 0.2805\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 903us/step - loss: 0.3228 - mse: 0.2832\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 868us/step - loss: 0.3162 - mse: 0.2773\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 936us/step - loss: 0.3146 - mse: 0.2763\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 941us/step - loss: 0.3184 - mse: 0.2809\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 927us/step - loss: 0.3162 - mse: 0.2794\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 898us/step - loss: 0.3116 - mse: 0.2754\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.3115 - mse: 0.2760\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 952us/step - loss: 0.3103 - mse: 0.2753\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 884us/step - loss: 0.3130 - mse: 0.2787\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 873us/step - loss: 0.3148 - mse: 0.2810\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 913us/step - loss: 0.3125 - mse: 0.2794\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 929us/step - loss: 0.3137 - mse: 0.2811\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 873us/step - loss: 0.3103 - mse: 0.2783\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 926us/step - loss: 0.3077 - mse: 0.2762\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 880us/step - loss: 0.3094 - mse: 0.2785\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 902us/step - loss: 0.3079 - mse: 0.2775\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3070 - mse: 0.2772\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 872us/step - loss: 0.3057 - mse: 0.2763\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3017 - mse: 0.2729\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.3041 - mse: 0.2758\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 877us/step - loss: 0.3085 - mse: 0.2807\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 937us/step - loss: 0.2991 - mse: 0.2717\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 962us/step - loss: 0.3008 - mse: 0.2739\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 868us/step - loss: 0.2987 - mse: 0.2722\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 924us/step - loss: 0.3003 - mse: 0.2743\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3009 - mse: 0.2753\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2982 - mse: 0.2731\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 908us/step - loss: 0.3099 - mse: 0.2853\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 870us/step - loss: 0.3027 - mse: 0.2784\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 869us/step - loss: 0.2957 - mse: 0.2718\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2989 - mse: 0.2754\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2918 - mse: 0.2688\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.3024 - mse: 0.2798\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 906us/step - loss: 0.2966 - mse: 0.2743\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 878us/step - loss: 0.2929 - mse: 0.2709\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 927us/step - loss: 0.2935 - mse: 0.2719\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 894us/step - loss: 0.2881 - mse: 0.2669\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 914us/step - loss: 0.2928 - mse: 0.2719\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 872us/step - loss: 0.2891 - mse: 0.2685\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2955 - mse: 0.2753\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2912 - mse: 0.2713\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2902 - mse: 0.2706\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 863us/step - loss: 0.2900 - mse: 0.2707\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.2941 - mse: 0.2752\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2891 - mse: 0.2704\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2904 - mse: 0.2720\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2894 - mse: 0.2714\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 870us/step - loss: 0.2943 - mse: 0.2766\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.2944 - mse: 0.2769\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2907 - mse: 0.2735\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2841 - mse: 0.2671\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 872us/step - loss: 0.2857 - mse: 0.2690\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.2840 - mse: 0.2676\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.2854 - mse: 0.2692\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2839 - mse: 0.2679\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 855us/step - loss: 0.2843 - mse: 0.2686\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 885us/step - loss: 0.2855 - mse: 0.2701\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 871us/step - loss: 0.2864 - mse: 0.2711\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.2862 - mse: 0.2712\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2828 - mse: 0.2681\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2821 - mse: 0.2676\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.2839 - mse: 0.2696\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.2815 - mse: 0.2674\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 879us/step - loss: 0.2824 - mse: 0.2685\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2869 - mse: 0.2732\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 953us/step - loss: 0.2786 - mse: 0.2651\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 926us/step - loss: 0.2829 - mse: 0.2696\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2858 - mse: 0.2727\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2821 - mse: 0.2692\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.2799 - mse: 0.2672\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 946us/step - loss: 0.2779 - mse: 0.2653\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 936us/step - loss: 0.2820 - mse: 0.2697\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 936us/step - loss: 0.2869 - mse: 0.2747\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 941us/step - loss: 0.2850 - mse: 0.2730\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 952us/step - loss: 0.2826 - mse: 0.2707\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 881us/step - loss: 0.2751 - mse: 0.2634\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 944us/step - loss: 0.2794 - mse: 0.2678\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 912us/step - loss: 0.2743 - mse: 0.2630\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 915us/step - loss: 0.2737 - mse: 0.2625\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 989us/step - loss: 0.2779 - mse: 0.2668\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 913us/step - loss: 0.2758 - mse: 0.2649\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 949us/step - loss: 0.2793 - mse: 0.2685\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 872us/step - loss: 0.2811 - mse: 0.2705\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.2803 - mse: 0.2698\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 905us/step - loss: 0.2829 - mse: 0.2726\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 869us/step - loss: 0.2806 - mse: 0.2704\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 907us/step - loss: 0.2798 - mse: 0.2697\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 895us/step - loss: 0.2750 - mse: 0.2650\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 874us/step - loss: 0.2792 - mse: 0.2694\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2809 - mse: 0.2712\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.2764 - mse: 0.2668\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2835 - mse: 0.2741\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.2784 - mse: 0.2691\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2745 - mse: 0.2653\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2771 - mse: 0.2680\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 947us/step - loss: 0.2779 - mse: 0.2689\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2784 - mse: 0.2695\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2719 - mse: 0.2632\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2774 - mse: 0.2687\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.2762 - mse: 0.2677\n",
      "Epoch 168/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2730 - mse: 0.2645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 821us/step - loss: 0.2699 - mse: 0.2616\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2736 - mse: 0.2653\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2799 - mse: 0.2717\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2706 - mse: 0.2626\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.2711 - mse: 0.2631\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2753 - mse: 0.2675\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2732 - mse: 0.2654\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.2756 - mse: 0.2678\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2681 - mse: 0.2605\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.2702 - mse: 0.2627\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2701 - mse: 0.2627\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2709 - mse: 0.2636\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.2763 - mse: 0.2690\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.2757 - mse: 0.2685\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2738 - mse: 0.2667\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 870us/step - loss: 0.2785 - mse: 0.2715\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.2718 - mse: 0.2649\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2737 - mse: 0.2669\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2793 - mse: 0.2726\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2716 - mse: 0.2649\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2760 - mse: 0.2694\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2735 - mse: 0.2669\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2727 - mse: 0.2662\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 824us/step - loss: 0.2696 - mse: 0.2632\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2712 - mse: 0.2648\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 816us/step - loss: 0.2748 - mse: 0.2684\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2770 - mse: 0.2707\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2779 - mse: 0.2717\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.2797 - mse: 0.2736\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 894us/step - loss: 0.2744 - mse: 0.2683\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2667 - mse: 0.2607\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2727 - mse: 0.2668\n",
      "23/23 [==============================] - 0s 628us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://8841802c3de34b30bd28807692a2888a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://8841802c3de34b30bd28807692a2888a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:22:03.520217: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://058159b046dc4f4e8d6957f52a20fb97: INVALID_ARGUMENT: ram://058159b046dc4f4e8d6957f52a20fb97 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 928us/step - loss: 0.7277 - mse: 0.5848\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 855us/step - loss: 0.5692 - mse: 0.4295\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.5350 - mse: 0.3983\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.5082 - mse: 0.3744\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.4982 - mse: 0.3672\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.4885 - mse: 0.3602\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.4736 - mse: 0.3478\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.4649 - mse: 0.3417\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.4491 - mse: 0.3284\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.4499 - mse: 0.3316\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.4478 - mse: 0.3318\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.4327 - mse: 0.3191\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.4271 - mse: 0.3157\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 824us/step - loss: 0.4218 - mse: 0.3125\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.4223 - mse: 0.3152\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.4154 - mse: 0.3104\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.4136 - mse: 0.3107\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.4108 - mse: 0.3098\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.4053 - mse: 0.3062\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.4022 - mse: 0.3051\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3986 - mse: 0.3033\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.3936 - mse: 0.3001\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.3946 - mse: 0.3029\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3903 - mse: 0.3004\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.3869 - mse: 0.2987\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3824 - mse: 0.2959\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.3752 - mse: 0.2904\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3757 - mse: 0.2924\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.3743 - mse: 0.2927\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.3734 - mse: 0.2933\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3707 - mse: 0.2921\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.3712 - mse: 0.2941\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 876us/step - loss: 0.3620 - mse: 0.2863\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.3644 - mse: 0.2902\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3629 - mse: 0.2901\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.3574 - mse: 0.2859\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.3553 - mse: 0.2852\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.3620 - mse: 0.2932\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.3566 - mse: 0.2891\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 874us/step - loss: 0.3532 - mse: 0.2870\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 814us/step - loss: 0.3481 - mse: 0.2831\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.3476 - mse: 0.2838\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.3504 - mse: 0.2878\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.3421 - mse: 0.2807\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.3388 - mse: 0.2784\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 864us/step - loss: 0.3440 - mse: 0.2848\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.3380 - mse: 0.2799\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.3407 - mse: 0.2837\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3426 - mse: 0.2866\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.3340 - mse: 0.2790\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.3305 - mse: 0.2765\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.3293 - mse: 0.2763\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.3320 - mse: 0.2800\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.3389 - mse: 0.2879\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 972us/step - loss: 0.3282 - mse: 0.2780\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 872us/step - loss: 0.3252 - mse: 0.2760\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.3272 - mse: 0.2788\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.3167 - mse: 0.2692\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.3230 - mse: 0.2764\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3206 - mse: 0.2749\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3188 - mse: 0.2739\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.3195 - mse: 0.2753\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.3248 - mse: 0.2815\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3160 - mse: 0.2735\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 824us/step - loss: 0.3152 - mse: 0.2735\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.3174 - mse: 0.2764\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 855us/step - loss: 0.3084 - mse: 0.2681\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 899us/step - loss: 0.3172 - mse: 0.2777\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 909us/step - loss: 0.3190 - mse: 0.2802\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3086 - mse: 0.2705\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 855us/step - loss: 0.3143 - mse: 0.2769\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.3127 - mse: 0.2760\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.3073 - mse: 0.2712\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.3138 - mse: 0.2783\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.3078 - mse: 0.2729\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.3081 - mse: 0.2738\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.3062 - mse: 0.2726\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.3038 - mse: 0.2707\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 877us/step - loss: 0.2998 - mse: 0.2673\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.3029 - mse: 0.2710\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 867us/step - loss: 0.3100 - mse: 0.2786\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 871us/step - loss: 0.2947 - mse: 0.2639\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.2967 - mse: 0.2664\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 937us/step - loss: 0.3049 - mse: 0.2751\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 886us/step - loss: 0.3062 - mse: 0.2769\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2931 - mse: 0.2643\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.3031 - mse: 0.2749\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2941 - mse: 0.2663\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2949 - mse: 0.2675\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.2987 - mse: 0.2718\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.3002 - mse: 0.2738\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.2925 - mse: 0.2666\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 938us/step - loss: 0.2931 - mse: 0.2676\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.2945 - mse: 0.2694\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.2955 - mse: 0.2708\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 889us/step - loss: 0.2883 - mse: 0.2640\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 863us/step - loss: 0.2906 - mse: 0.2668\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 818us/step - loss: 0.2901 - mse: 0.2666\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 821us/step - loss: 0.2935 - mse: 0.2704\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2911 - mse: 0.2684\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.2883 - mse: 0.2660\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2873 - mse: 0.2653\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2849 - mse: 0.2633\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2872 - mse: 0.2659\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2799 - mse: 0.2590\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2911 - mse: 0.2705\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2866 - mse: 0.2665\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2895 - mse: 0.2696\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2865 - mse: 0.2670\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.2897 - mse: 0.2705\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.2897 - mse: 0.2708\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 902us/step - loss: 0.2869 - mse: 0.2683\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2872 - mse: 0.2689\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2838 - mse: 0.2657\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.2852 - mse: 0.2674\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.2842 - mse: 0.2667\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2871 - mse: 0.2699\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 819us/step - loss: 0.2787 - mse: 0.2618\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 821us/step - loss: 0.2883 - mse: 0.2716\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.2775 - mse: 0.2611\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.2830 - mse: 0.2669\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2860 - mse: 0.2701\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2852 - mse: 0.2695\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2812 - mse: 0.2658\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 909us/step - loss: 0.2831 - mse: 0.2679\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.2823 - mse: 0.2674\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.2798 - mse: 0.2651\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.2832 - mse: 0.2687\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 856us/step - loss: 0.2806 - mse: 0.2664\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.2790 - mse: 0.2650\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2734 - mse: 0.2596\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 873us/step - loss: 0.2843 - mse: 0.2707\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2822 - mse: 0.2687\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 867us/step - loss: 0.2769 - mse: 0.2637\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2767 - mse: 0.2636\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2778 - mse: 0.2650\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 953us/step - loss: 0.2735 - mse: 0.2608\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.2769 - mse: 0.2644\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 960us/step - loss: 0.2795 - mse: 0.2672\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 975us/step - loss: 0.2768 - mse: 0.2647\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 913us/step - loss: 0.2798 - mse: 0.2679\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 880us/step - loss: 0.2715 - mse: 0.2597\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.2714 - mse: 0.2598\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 943us/step - loss: 0.2790 - mse: 0.2675\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.2736 - mse: 0.2623\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 967us/step - loss: 0.2771 - mse: 0.2660\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.2772 - mse: 0.2662\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 865us/step - loss: 0.2737 - mse: 0.2629\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.2744 - mse: 0.2637\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 875us/step - loss: 0.2750 - mse: 0.2644\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.2770 - mse: 0.2665\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2769 - mse: 0.2666\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.2732 - mse: 0.2631\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2704 - mse: 0.2604\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.2741 - mse: 0.2642\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.2717 - mse: 0.2620\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2720 - mse: 0.2624\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2749 - mse: 0.2654\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2763 - mse: 0.2669\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2742 - mse: 0.2649\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2679 - mse: 0.2587\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 859us/step - loss: 0.2708 - mse: 0.2618\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.2764 - mse: 0.2675\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2710 - mse: 0.2622\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.2710 - mse: 0.2623\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.2751 - mse: 0.2665\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 940us/step - loss: 0.2709 - mse: 0.2624\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 859us/step - loss: 0.2696 - mse: 0.2612\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.2701 - mse: 0.2618\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.2734 - mse: 0.2652\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2712 - mse: 0.2630\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.2710 - mse: 0.2630\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.2759 - mse: 0.2680\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.2677 - mse: 0.2599\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.2697 - mse: 0.2620\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2761 - mse: 0.2685\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.2646 - mse: 0.2570\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.2664 - mse: 0.2589\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.2706 - mse: 0.2632\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.2611 - mse: 0.2538\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2719 - mse: 0.2647\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2687 - mse: 0.2615\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2713 - mse: 0.2642\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2699 - mse: 0.2629\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2749 - mse: 0.2680\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2637 - mse: 0.2569\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2676 - mse: 0.2608\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.2723 - mse: 0.2656\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2692 - mse: 0.2626\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2673 - mse: 0.2607\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.2694 - mse: 0.2629\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.2677 - mse: 0.2613\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 864us/step - loss: 0.2717 - mse: 0.2654\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2652 - mse: 0.2589\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 858us/step - loss: 0.2684 - mse: 0.2621\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.2663 - mse: 0.2601\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2664 - mse: 0.2603\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2704 - mse: 0.2643\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2669 - mse: 0.2609\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.2663 - mse: 0.2603\n",
      "23/23 [==============================] - 0s 581us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://8afb1e3cc20c4db48c916f2084b0dbe1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://8afb1e3cc20c4db48c916f2084b0dbe1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:22:20.380637: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://383f738dbd134df8acb12783808e625f: INVALID_ARGUMENT: ram://383f738dbd134df8acb12783808e625f is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 922us/step - loss: 0.7233 - mse: 0.5803\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 899us/step - loss: 0.5677 - mse: 0.4279\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 882us/step - loss: 0.5351 - mse: 0.3984\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 884us/step - loss: 0.5159 - mse: 0.3821\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.4932 - mse: 0.3622\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.4844 - mse: 0.3561\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.4833 - mse: 0.3576\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.4640 - mse: 0.3409\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 820us/step - loss: 0.4598 - mse: 0.3392\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.4517 - mse: 0.3335\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.4456 - mse: 0.3297\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.4361 - mse: 0.3225\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 812us/step - loss: 0.4345 - mse: 0.3231\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.4289 - mse: 0.3197\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.4161 - mse: 0.3090\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.4178 - mse: 0.3128\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.4155 - mse: 0.3125\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.4070 - mse: 0.3060\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.4054 - mse: 0.3064\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 818us/step - loss: 0.4030 - mse: 0.3059\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.4072 - mse: 0.3119\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.3966 - mse: 0.3032\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.3953 - mse: 0.3037\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.3950 - mse: 0.3051\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.3878 - mse: 0.2997\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.3809 - mse: 0.2945\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 861us/step - loss: 0.3814 - mse: 0.2965\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.3822 - mse: 0.2989\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.3760 - mse: 0.2943\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.3774 - mse: 0.2973\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.3743 - mse: 0.2957\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.3688 - mse: 0.2917\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.3641 - mse: 0.2884\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.3680 - mse: 0.2938\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.3592 - mse: 0.2863\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 933us/step - loss: 0.3643 - mse: 0.2928\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3602 - mse: 0.2901\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.3630 - mse: 0.2941\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.3563 - mse: 0.2888\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.3549 - mse: 0.2885\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3545 - mse: 0.2894\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 894us/step - loss: 0.3538 - mse: 0.2900\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3498 - mse: 0.2871\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 815us/step - loss: 0.3463 - mse: 0.2848\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.3458 - mse: 0.2854\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.3451 - mse: 0.2858\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.3461 - mse: 0.2879\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.3378 - mse: 0.2807\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.3410 - mse: 0.2850\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.3379 - mse: 0.2829\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 859us/step - loss: 0.3404 - mse: 0.2864\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.3348 - mse: 0.2818\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.3316 - mse: 0.2796\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.3285 - mse: 0.2774\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3319 - mse: 0.2817\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.3335 - mse: 0.2843\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.3294 - mse: 0.2811\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.3227 - mse: 0.2753\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.3230 - mse: 0.2765\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.3302 - mse: 0.2845\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.3251 - mse: 0.2802\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.3261 - mse: 0.2820\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.3218 - mse: 0.2785\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.3173 - mse: 0.2748\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.3203 - mse: 0.2785\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.3193 - mse: 0.2783\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.3177 - mse: 0.2774\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.3179 - mse: 0.2783\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.3106 - mse: 0.2718\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 859us/step - loss: 0.3145 - mse: 0.2763\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 881us/step - loss: 0.3136 - mse: 0.2761\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 821us/step - loss: 0.3082 - mse: 0.2713\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.3075 - mse: 0.2714\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3131 - mse: 0.2775\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.3095 - mse: 0.2746\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.3072 - mse: 0.2729\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.3101 - mse: 0.2764\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.3068 - mse: 0.2737\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.3071 - mse: 0.2746\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3050 - mse: 0.2731\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.3090 - mse: 0.2776\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.3011 - mse: 0.2702\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.3000 - mse: 0.2696\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.3087 - mse: 0.2788\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 844us/step - loss: 0.3022 - mse: 0.2729\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 819us/step - loss: 0.3007 - mse: 0.2719\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 911us/step - loss: 0.3014 - mse: 0.2730\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.3062 - mse: 0.2784\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.3027 - mse: 0.2754\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.3014 - mse: 0.2744\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 819us/step - loss: 0.3025 - mse: 0.2760\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2956 - mse: 0.2696\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2951 - mse: 0.2696\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2997 - mse: 0.2746\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.2977 - mse: 0.2730\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2971 - mse: 0.2728\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 871us/step - loss: 0.2906 - mse: 0.2667\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2952 - mse: 0.2716\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.2955 - mse: 0.2724\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 824us/step - loss: 0.2960 - mse: 0.2733\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.2992 - mse: 0.2768\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2935 - mse: 0.2714\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.2974 - mse: 0.2757\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 819us/step - loss: 0.2918 - mse: 0.2705\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2903 - mse: 0.2693\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2893 - mse: 0.2687\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2837 - mse: 0.2634\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2909 - mse: 0.2709\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.2852 - mse: 0.2656\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2872 - mse: 0.2679\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.2845 - mse: 0.2655\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2958 - mse: 0.2771\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2913 - mse: 0.2729\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.2902 - mse: 0.2721\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2887 - mse: 0.2709\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2861 - mse: 0.2685\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2867 - mse: 0.2695\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2827 - mse: 0.2657\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2868 - mse: 0.2700\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2859 - mse: 0.2694\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 855us/step - loss: 0.2785 - mse: 0.2623\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.2868 - mse: 0.2708\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.2832 - mse: 0.2674\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.2839 - mse: 0.2684\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 855us/step - loss: 0.2868 - mse: 0.2715\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2782 - mse: 0.2631\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 855us/step - loss: 0.2817 - mse: 0.2669\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2881 - mse: 0.2735\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.2810 - mse: 0.2667\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.2794 - mse: 0.2653\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.2837 - mse: 0.2697\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2812 - mse: 0.2674\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 816us/step - loss: 0.2839 - mse: 0.2703\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2792 - mse: 0.2659\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.2789 - mse: 0.2658\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.2754 - mse: 0.2624\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 811us/step - loss: 0.2794 - mse: 0.2666\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2788 - mse: 0.2662\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2731 - mse: 0.2606\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2751 - mse: 0.2628\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.2784 - mse: 0.2663\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2833 - mse: 0.2713\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2824 - mse: 0.2706\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2781 - mse: 0.2665\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 818us/step - loss: 0.2818 - mse: 0.2703\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2787 - mse: 0.2674\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.2783 - mse: 0.2672\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 800us/step - loss: 0.2776 - mse: 0.2666\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2757 - mse: 0.2648\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 801us/step - loss: 0.2759 - mse: 0.2652\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 816us/step - loss: 0.2767 - mse: 0.2661\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 819us/step - loss: 0.2799 - mse: 0.2695\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2778 - mse: 0.2675\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.2738 - mse: 0.2636\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.2775 - mse: 0.2675\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 902us/step - loss: 0.2703 - mse: 0.2604\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 884us/step - loss: 0.2821 - mse: 0.2724\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.2771 - mse: 0.2674\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.2791 - mse: 0.2695\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 885us/step - loss: 0.2758 - mse: 0.2664\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 895us/step - loss: 0.2720 - mse: 0.2627\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 927us/step - loss: 0.2733 - mse: 0.2642\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 893us/step - loss: 0.2784 - mse: 0.2693\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.2720 - mse: 0.2630\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2797 - mse: 0.2709\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2694 - mse: 0.2606\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.2751 - mse: 0.2665\n",
      "Epoch 168/200\n",
      "91/91 [==============================] - 0s 913us/step - loss: 0.2739 - mse: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2707 - mse: 0.2623\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.2771 - mse: 0.2688\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2762 - mse: 0.2680\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.2729 - mse: 0.2649\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2749 - mse: 0.2669\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.2768 - mse: 0.2688\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 854us/step - loss: 0.2755 - mse: 0.2677\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2738 - mse: 0.2660\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2729 - mse: 0.2653\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.2717 - mse: 0.2642\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2741 - mse: 0.2667\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 819us/step - loss: 0.2719 - mse: 0.2645\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 810us/step - loss: 0.2729 - mse: 0.2656\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 812us/step - loss: 0.2708 - mse: 0.2636\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 821us/step - loss: 0.2707 - mse: 0.2636\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 817us/step - loss: 0.2741 - mse: 0.2671\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.2695 - mse: 0.2626\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2657 - mse: 0.2588\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.2690 - mse: 0.2621\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2700 - mse: 0.2633\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2679 - mse: 0.2612\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2698 - mse: 0.2631\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 818us/step - loss: 0.2703 - mse: 0.2638\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 819us/step - loss: 0.2703 - mse: 0.2637\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.2676 - mse: 0.2611\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2745 - mse: 0.2681\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2720 - mse: 0.2657\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 824us/step - loss: 0.2732 - mse: 0.2669\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2680 - mse: 0.2618\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2667 - mse: 0.2605\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.2722 - mse: 0.2661\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.2712 - mse: 0.2652\n",
      "23/23 [==============================] - 0s 573us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4fd4f2461ae94aa089fa89734fddcd3d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4fd4f2461ae94aa089fa89734fddcd3d/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:22:36.996971: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ram://4b7466647d8c49b3b789b119f3f04d71: INVALID_ARGUMENT: ram://4b7466647d8c49b3b789b119f3f04d71 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 907us/step - loss: 0.7170 - mse: 0.5740\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.5651 - mse: 0.4252\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.5350 - mse: 0.3982\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 849us/step - loss: 0.5085 - mse: 0.3746\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 855us/step - loss: 0.4934 - mse: 0.3623\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 821us/step - loss: 0.4798 - mse: 0.3514\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.4720 - mse: 0.3463\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.4650 - mse: 0.3418\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.4546 - mse: 0.3339\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.4449 - mse: 0.3266\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.4366 - mse: 0.3206\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 858us/step - loss: 0.4420 - mse: 0.3284\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 906us/step - loss: 0.4273 - mse: 0.3159\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.4232 - mse: 0.3140\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.4152 - mse: 0.3081\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.4125 - mse: 0.3074\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.4071 - mse: 0.3041\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.4145 - mse: 0.3136\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.4050 - mse: 0.3060\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.3993 - mse: 0.3022\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.3940 - mse: 0.2987\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.3960 - mse: 0.3025\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3877 - mse: 0.2960\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3876 - mse: 0.2976\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 824us/step - loss: 0.3899 - mse: 0.3017\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 877us/step - loss: 0.3805 - mse: 0.2939\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3790 - mse: 0.2941\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.3822 - mse: 0.2988\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.3757 - mse: 0.2940\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 867us/step - loss: 0.3642 - mse: 0.2840\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.3632 - mse: 0.2845\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.3705 - mse: 0.2933\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 824us/step - loss: 0.3630 - mse: 0.2872\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.3666 - mse: 0.2922\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.3596 - mse: 0.2866\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.3591 - mse: 0.2875\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.3597 - mse: 0.2895\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.3570 - mse: 0.2881\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.3493 - mse: 0.2817\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.3499 - mse: 0.2836\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.3528 - mse: 0.2877\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.3444 - mse: 0.2805\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3505 - mse: 0.2877\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.3447 - mse: 0.2831\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.3387 - mse: 0.2783\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.3408 - mse: 0.2815\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.3411 - mse: 0.2829\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 851us/step - loss: 0.3445 - mse: 0.2874\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.3386 - mse: 0.2825\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.3413 - mse: 0.2863\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.3384 - mse: 0.2844\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 821us/step - loss: 0.3296 - mse: 0.2766\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 864us/step - loss: 0.3305 - mse: 0.2785\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.3332 - mse: 0.2821\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.3236 - mse: 0.2734\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.3322 - mse: 0.2829\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.3237 - mse: 0.2753\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.3248 - mse: 0.2773\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3238 - mse: 0.2772\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.3230 - mse: 0.2772\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.3196 - mse: 0.2746\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.3259 - mse: 0.2818\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.3156 - mse: 0.2723\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3101 - mse: 0.2675\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3143 - mse: 0.2725\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.3154 - mse: 0.2744\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.3170 - mse: 0.2767\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.3181 - mse: 0.2785\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.3087 - mse: 0.2698\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.3065 - mse: 0.2682\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.3134 - mse: 0.2759\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 896us/step - loss: 0.3061 - mse: 0.2692\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 853us/step - loss: 0.3108 - mse: 0.2746\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 824us/step - loss: 0.3025 - mse: 0.2669\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.3058 - mse: 0.2709\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.3051 - mse: 0.2707\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.3084 - mse: 0.2747\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.3067 - mse: 0.2735\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.3053 - mse: 0.2727\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 859us/step - loss: 0.3027 - mse: 0.2707\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.3058 - mse: 0.2744\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2973 - mse: 0.2663\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 856us/step - loss: 0.2992 - mse: 0.2689\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.3009 - mse: 0.2711\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 845us/step - loss: 0.3061 - mse: 0.2768\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.2958 - mse: 0.2670\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.3036 - mse: 0.2752\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2992 - mse: 0.2714\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 811us/step - loss: 0.2931 - mse: 0.2657\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 865us/step - loss: 0.2935 - mse: 0.2666\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.2964 - mse: 0.2699\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2939 - mse: 0.2678\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 813us/step - loss: 0.2908 - mse: 0.2652\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2981 - mse: 0.2730\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2952 - mse: 0.2705\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.2871 - mse: 0.2628\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 811us/step - loss: 0.2940 - mse: 0.2700\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.2922 - mse: 0.2687\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2910 - mse: 0.2678\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2886 - mse: 0.2658\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 834us/step - loss: 0.2936 - mse: 0.2712\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2931 - mse: 0.2712\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 861us/step - loss: 0.2846 - mse: 0.2630\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2871 - mse: 0.2659\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2836 - mse: 0.2627\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.2891 - mse: 0.2686\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2856 - mse: 0.2654\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 828us/step - loss: 0.2846 - mse: 0.2647\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2868 - mse: 0.2672\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2850 - mse: 0.2657\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 839us/step - loss: 0.2784 - mse: 0.2595\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2856 - mse: 0.2670\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2869 - mse: 0.2686\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2913 - mse: 0.2733\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2842 - mse: 0.2664\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.2866 - mse: 0.2691\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.2840 - mse: 0.2667\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2824 - mse: 0.2654\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 814us/step - loss: 0.2840 - mse: 0.2673\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2854 - mse: 0.2689\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2842 - mse: 0.2680\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2828 - mse: 0.2669\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2782 - mse: 0.2625\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.2822 - mse: 0.2667\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2755 - mse: 0.2602\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2824 - mse: 0.2674\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.2842 - mse: 0.2694\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2754 - mse: 0.2609\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2755 - mse: 0.2612\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2800 - mse: 0.2658\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.2778 - mse: 0.2639\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 825us/step - loss: 0.2762 - mse: 0.2625\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 894us/step - loss: 0.2772 - mse: 0.2637\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 850us/step - loss: 0.2747 - mse: 0.2614\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2782 - mse: 0.2651\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 830us/step - loss: 0.2804 - mse: 0.2674\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2794 - mse: 0.2666\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2740 - mse: 0.2614\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 837us/step - loss: 0.2754 - mse: 0.2629\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 829us/step - loss: 0.2760 - mse: 0.2638\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 835us/step - loss: 0.2778 - mse: 0.2657\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 846us/step - loss: 0.2766 - mse: 0.2647\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 840us/step - loss: 0.2772 - mse: 0.2655\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.2774 - mse: 0.2659\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2721 - mse: 0.2607\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 831us/step - loss: 0.2699 - mse: 0.2587\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 862us/step - loss: 0.2743 - mse: 0.2632\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 832us/step - loss: 0.2707 - mse: 0.2597\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 823us/step - loss: 0.2718 - mse: 0.2610\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2763 - mse: 0.2657\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 925us/step - loss: 0.2725 - mse: 0.2620\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 925us/step - loss: 0.2757 - mse: 0.2653\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 886us/step - loss: 0.2717 - mse: 0.2615\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 870us/step - loss: 0.2703 - mse: 0.2602\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.2746 - mse: 0.2647\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 956us/step - loss: 0.2665 - mse: 0.2567\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 905us/step - loss: 0.2654 - mse: 0.2557\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 908us/step - loss: 0.2726 - mse: 0.2630\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 914us/step - loss: 0.2744 - mse: 0.2650\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 901us/step - loss: 0.2682 - mse: 0.2589\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 912us/step - loss: 0.2725 - mse: 0.2634\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 860us/step - loss: 0.2764 - mse: 0.2673\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 883us/step - loss: 0.2736 - mse: 0.2646\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 848us/step - loss: 0.2733 - mse: 0.2644\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 870us/step - loss: 0.2697 - mse: 0.2610\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 900us/step - loss: 0.2672 - mse: 0.2586\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 900us/step - loss: 0.2707 - mse: 0.2621\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 954us/step - loss: 0.2720 - mse: 0.2635\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 896us/step - loss: 0.2724 - mse: 0.2640\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2711 - mse: 0.2628\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 920us/step - loss: 0.2726 - mse: 0.2644\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2722 - mse: 0.2642\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.2739 - mse: 0.2659\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.2732 - mse: 0.2653\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 913us/step - loss: 0.2706 - mse: 0.2628\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 882us/step - loss: 0.2704 - mse: 0.2627\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 880us/step - loss: 0.2633 - mse: 0.2557\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.2689 - mse: 0.2614\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 847us/step - loss: 0.2661 - mse: 0.2586\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 861us/step - loss: 0.2661 - mse: 0.2587\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.2682 - mse: 0.2609\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 997us/step - loss: 0.2668 - mse: 0.2596\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2712 - mse: 0.2641\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2666 - mse: 0.2596\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 921us/step - loss: 0.2680 - mse: 0.2611\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 939us/step - loss: 0.2651 - mse: 0.2582\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 922us/step - loss: 0.2728 - mse: 0.2660\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 866us/step - loss: 0.2689 - mse: 0.2621\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 858us/step - loss: 0.2636 - mse: 0.2569\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 842us/step - loss: 0.2626 - mse: 0.2560\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 827us/step - loss: 0.2689 - mse: 0.2623\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 844us/step - loss: 0.2712 - mse: 0.2648\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 841us/step - loss: 0.2609 - mse: 0.2545\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 833us/step - loss: 0.2654 - mse: 0.2590\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 838us/step - loss: 0.2620 - mse: 0.2557\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 852us/step - loss: 0.2727 - mse: 0.2665\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 826us/step - loss: 0.2688 - mse: 0.2627\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 843us/step - loss: 0.2697 - mse: 0.2636\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 845us/step - loss: 0.2659 - mse: 0.2599\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 836us/step - loss: 0.2703 - mse: 0.2644\n",
      "23/23 [==============================] - 0s 567us/step\n"
     ]
    }
   ],
   "source": [
    "keras_wrapper_4 = KerasRegressor(create_regularized_model2(), epochs=200, batch_size=256)\n",
    "cv_l2_preds = cross_val_predict(keras_wrapper_4, X_train_all, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4427503805468388"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_train_scaled, cv_l2_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation\n",
    "\n",
    "Now that you have selected a network architecture, tested various regularization procedures and tuned hyperparameters via a validation methodology, it is time to evaluate your final model on the test set. Fit the model using all of the training data using the architecture and hyperparameters that were most effective in your experiments above. Afterwards, measure the overall performance on the hold-out test data which has been left untouched (and hasn't leaked any data into the modeling process)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1869f79a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  This cell may take several mintes to run\n",
    "best_model = create_bigger_model()\n",
    "best_model.fit(X_train_all,\n",
    "               y_train_scaled,\n",
    "               epochs=150,\n",
    "               batch_size=256,\n",
    "               verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 [==============================] - 0s 479us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3926.0490515659467"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# un-scale predictions, to increase interpretability\n",
    "\n",
    "y_test_preds_scaled = best_model.predict(X_test_all)\n",
    "\n",
    "y_test_preds = ss_y.inverse_transform(y_test_preds_scaled)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you investigated some data from *The Lending Club* in a complete data science pipeline to build neural networks with good performance. You began with reserving a hold-out set for testing which never was touched during the modeling phase. From there, you implemented a k-fold cross validation methodology in order to assess an initial baseline model and various regularization methods. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nn)",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
